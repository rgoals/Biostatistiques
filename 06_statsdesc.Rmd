---
title: "Biostatistiques"
author: "Serge-√âtienne Parent"
date: "`r format(Sys.Date())`"
output: github_document
---

# Statistiques descriptives {#chapitre-statsdesc}

 ***
Ô∏è\ **Objectifs sp√©cifiques**:





 ***

## Sommaire des donn√©es

Nous avons vu comment g√©n√©rer des statistiques sommaires en **R** avec la fonction `summary()`. Reprenons les donn√©es d'iris.

```{r warning = FALSE, message = FALSE}
library("tidyverse")
data("iris")
```

```{r}
head(iris)
```

```{r}
summary(iris)
```

## Moyenne et √©cart-type

Pour pr√©cis√©ment effectuer **une moyenne** et **un √©cart-type** sur un vecteur, passons par les fonctions `mean()` et `sd()`.

```{r}
mean(iris$Sepal.Length)
sd(iris$Sepal.Length)
```

Pour effectuer un sommaire de tableau pilot√© par une fonction, nous passons par la gamme de fonctions `summarise()`, de `dplyr`. Dans ce cas, avec `group_by()`, nous fragmentons le tableau par esp√®ce pour effectuer un sommaire sur toutes les variables.

```{r}
iris %>%
  group_by(Species) %>%
  summarise_all(mean)
```

## Quartiles

Vous pourriez √™tre int√©ress√© par **les quartiles** √† 25%, 50% et 75%. Mais la fonction `summarise()` n'autorise que les fonctions dont la sortie est d'un seul objet, alors faisons de sorte que l'objet soit une liste - lorsque l'on imbrique une fonction `funs`, le tableau √† ins√©rer dans la fonction est indiqu√© par un **`.`**.

```{r}
iris %>%
  group_by(Species) %>%
  summarise_all(tibble::lst(mean, median))
```

En mode programmation classique de **R**, on pourra g√©n√©rer les quartiles √† la pi√®ce.

```{r}
quantile(iris$Sepal.Length[iris$Species == 'setosa'])
```

```{r}
quantile(iris$Sepal.Length[iris$Species == 'versicolor'])
```

```{r}
quantile(iris$Sepal.Length[iris$Species == 'virginica'])
```

## D√©comptes et proportions

La fonction `table()` permettra d'obtenir des **d√©comptes par cat√©gorie**, ici par plages de longueurs de s√©pales.

```{r}
tableau_croise <- table(iris$Species, 
                        cut(iris$Sepal.Length, breaks = quantile(iris$Sepal.Length)))
tableau_croise
```

Pour obtenir **les proportions** du nombre total, il s'agit d'encapsuler le tableau crois√© dans la fonction `prop.table()`.

```{r}
prop.table(tableau_croise)
```

## Tests d'hypoth√®ses √† 1 et 2 √©chantillons

Un [test d'hypoth√®se](https://help.xlstat.com/s/article/quest-ce-quun-test-statistique?language=fr) permet de d√©cider si une hypoth√®se est confirm√©e ou rejet√©e √† un seuil de probabilit√© pr√©d√©termin√©.

> En statistiques, un test d'hypoth√®ses (ou test statistique) est une proc√©dure de d√©cision entre deux hypoth√®ses. IC'est une d√©marche consistant √† rejeter ou √† ne pas rejeter une hypoth√®se statistique, appel√©e hypoth√®se nulle, en fonction d'un jeu de donn√©es.

Cette section est inspir√©e du chapitre 5 de [Dalgaard, 2008](https://www.springer.com/us/book/9780387790534).

---

### L'hypoth√®se nulle

Les tests d'hypoth√®se √©value des *effets* statistiques (qui ne sont pas n√©cessairement des effets de causalit√©). L'effet √† √©valuer peut √™tre celui d'un traitement, d'indicateurs m√©t√©orologiques (e.g. pr√©cipitations totales, degr√©-jour, etc.), de techniques de gestion des paysages, etc. Une recherche est men√©e pour √©valuer l'hypoth√®se que l'on retrouve des diff√©rences entre des unit√©s exp√©rimentales. Par convention, l'**hypoth√®se nulle** (√©crite $H_0$) est l'hypoth√®se qu'il n'y ait pas d'effet (c'est l'hypoth√®se de l'avocat du diable üòà) √† l'√©chelle de la population (et non pas √† l'√©chelle de l'√©chantillon). √Ä l'inverse, l'**hypoth√®se alternative** (√©crite $H_1$) est l'hypoth√®se qu'il y ait un effet √† l'√©chelle de la population.

----

√Ä titre d'exercice en stats, on d√©bute souvent par en testant si deux vecteurs de valeurs continues proviennent de populations √† moyennes diff√©rentes ou si un vecteur de valeurs a √©t√© g√©n√©r√© √† partir d'une population ayant une moyenne donner. Dans cette section, nous utiliserons la fonction `t.test()` pour les tests de t et la fonction `wilcox.test()` pour les tests de Wilcoxon (aussi appel√© de Mann-Whitney).

### Test de t √† un seul √©chantillon

Nous devons assumer, pour ce test, que l'√©chantillon est recueillit d'une population dont la distribution est normale, $\mathcal{N} \sim \left( \mu, \sigma^2 \right)$, et que chaque [√©chantillon est ind√©pendant](https://support.minitab.com/fr-fr/minitab/18/statistics/equivalence-tests/supporting-topics/how-are-dependent-and-independent-samples-different/) l'un de l'autre. L'hypoth√®se nulle est souvent celle de l'avocat du diable, que la moyenne soit √©gale √† une valeur donn√©e (_donc la diff√©rence entre la moyenne de la population et une moyenne donn√©e est de z√©ro_) : ici, que $\mu = \bar{x}$. L'erreur standard sur la moyenne (ESM) de l'√©chantillon, $\bar{x}$ est calcul√©e comme suit.

$$ESM = \frac{s}{\sqrt{n}}$$

o√π $s$ est l'√©cart-type de l'√©chantillon et $n$ est le nombre d'√©chantillons.

### Intervalle de confiance

Pour tester **l'intervalle de confiance** de l'√©chantillon, on multiplie l'ESM par l'aire sous la courbe de densit√© couvrant une certaine proportion de part et d'autre de l'√©chantillon. Pour un niveau de confiance de 95%, on retranche 2.5% de part et d'autre.

```{r}
set.seed(33746)
x <- rnorm(20, 16, 4)

level <-  0.95
alpha <- 1-level

x_bar <- mean(x)
s <- sd(x)
n <- length(x)

error <- qnorm(1 - alpha/2) * s / sqrt(n)
error
```

L'**intervalle de confiance** est l'erreur de par et d'autre de la moyenne.

```{r}
c(x_bar - error, x_bar + error)
```

Si la moyenne de la population est de 16, un nombre qui se situe dans l'intervalle de confiance on accepte l'hypoth√®se nulle au seuil 0.05. Si le nombre d'√©chantillon est r√©duit (g√©n√©ralement < 30), on passera plut√¥t par une distribution de t, avec $n-1$ degr√©s de libert√©.

```{r}
error <- qt(1 - alpha/2, n-1) * s / sqrt(n)
c(x_bar - error, x_bar + error)
```

Plus simplement, on pourra utiliser la fonction `t.test()` en sp√©cifiant la moyenne de la population. Nous avons g√©n√©r√© 20 donn√©es avec une moyenne de 16 et un √©cart-type de 4. Nous savons donc que la vraie moyenne de l'√©chantillon est de 16. Mais disons que nous testons l'hypoth√®se que ces donn√©es sont tir√©es d'une population dont la moyenne est 18 (et implicitement que sont √©cart-type est de 4).

```{r}
t.test(x, mu = 18)
```

La fonction retourne la valeur de t (*t-value*), le nombre de degr√©s de libert√© ($n-1 = 19$), une description de l'hypoth√®se alternative (`alternative hypothesis: true mean is not equal to 18`), ainsi que l'intervalle de confiance au niveau de 95%. Le test contient aussi la *p-value*. Bien que la *p-value* soit largement utilis√©e en science

----

### La *p-value*

La *p-value*, ou valeur-p ou p-valeur, est utilis√©e pour trancher si, oui ou non, un r√©sultat est **significatif** (en langage scientifique, le mot significatif ne devrait √™tre utilis√© *que* lorsque l'on r√©f√®re √† un test d'hypoth√®se statistique). Vous retrouverez des *p-value* partout en stats. Les *p-values* indiquent la confiance que l'hypoth√®se nulle soit vraie, selon les donn√©es et le mod√®le statistique utilis√©es.

> La p-value est la probabilit√© que les donn√©es aient √©t√© g√©n√©r√©es pour obtenir un effet √©quivalent ou plus prononc√© si l'hypoth√®se nulle est vraie.

Une *p-value* √©lev√©e indique que le mod√®le appliqu√© √† vos donn√©es concordent avec la conclusion que l'hypoth√®se nulle est vraie, et inversement si la *p-value* est faible. Le seuil arbitraire utilis√©e en √©cologie et en agriculture, comme dans plusieurs domaines, est 0.05.

Les six principes de l'[American Statistical Association](https://phys.org/news/2016-03-american-statistical-association-statement-significance.html) guident l'interpr√©tation des *p-values*. [ma traduction]

0. Les *p-values* indique l'ampleur de l‚Äôincompatibilit√© des donn√©es avec le mod√®le statistique
0. Les *p-values* ne mesurent pas la probabilit√© que l'hypoth√®se √©tudi√©e soit vraie, ni la probabilit√© que les donn√©es ont √©t√© g√©n√©r√©es uniquement par la chance.
0. Les conclusions scientifiques et d√©cisions d'affaire ou politiques ne devraient pas √™tre bas√©es sur si une *p-value* atteint un seuil sp√©cifique.
0. Une inf√©rence appropri√©e demande un rapport complet et transparent.
0. Une *p-value*, ou une signification statistique, ne mesure pas l'ampleur d'un effet ou l'importance d'un r√©sultat.
0. En tant que tel, une *p-value* n'offre pas une bonne mesure des √©vidences d'un mod√®le ou d'une hypoth√®se.

Cet encadr√© est inspir√© d'un [billet de blogue de Jim Frost](https://blog.minitab.com/blog/adventures-in-statistics-2/how-to-correctly-interpret-p-values) et d'un [rapport de l'American Statistical Association](https://phys.org/news/2016-03-american-statistical-association-statement-significance.html).

----

Dans le cas pr√©c√©dent, la *p-value* √©tait de 0.01014. Pour aider notre interpr√©tation, prenons l'hypoth√®se alternative: `true mean is not equal to 18`. L'hypoth√®se nulle √©tait bien que *la vraie moyenne est √©gale √† 18*. Ins√©rons la *p-value* dans la d√©finition: la probabilit√© que les donn√©es aient √©t√© g√©n√©r√©es pour obtenir un effet √©quivalent ou plus prononc√© si l'hypoth√®se nulle est vraie est de 0.01014. Il est donc tr√®s peu probable que les donn√©es soient tir√©es d'un √©chantillon dont la moyenne est de 18. Au seuil de signification de 0.05, on rejette l'hypoth√®se nulle et l'on conclut qu'√† ce seuil de confiance, l'√©chantillon ne provient pas d'une population ayant une moyenne de 18.

----

#### Attention aux mauvaises interpr√©tations des *p-values*

> "La p-value n'a jamais √©t√© con√ßue comme substitut au raisonnement scientifique" [Ron Wasserstein, directeur de l'American Statistical Association](https://phys.org/news/2016-03-american-statistical-association-statement-significance.html) [ma traduction]. 

**Un r√©sultat montrant une p-value plus √©lev√©e que 0.05 est-il pertinent?**

Lors d'une conf√©rence, Dr Evil ne pr√©sentent que les r√©sultats significatifs de ses essais au seuil de 0.05. Certains essais ne sont pas significatifs, mais bon, ceux-ci ne sont pas importants... En √©cartant ces r√©sultats, Dr Evil commet 3 erreurs:

1. La *p-value* n'est pas un bon indicateur de l'importance d'un test statistique. L'importance d'une variable dans un mod√®le devrait √™tre √©valu√©e par la valeur de son coefficient. Son incertitude devrait √™tre √©valu√©e par sa variance. Une mani√®re d'√©valuer plus intuitive la variance est l'√©cart-type ou l'intervalle de confiance. √Ä un certain seuil d'intervalle de confiance, la p-value traduira la probabilit√© qu'un coefficient soit r√©ellement nul ait pu g√©n√©rer des donn√©es d√©montrant un coefficient √©gal ou sup√©rieur.

1. Il est tout aussi important de savoir que le traitement fonctionne que de savoir qu'il ne fonctionne pas. Les r√©sultats d√©montrant des effets sont malheureusement davantage soumis aux journaux et davantage publi√©s que ceux ne d√©montrant pas d'effets ([Decullier et al., 2005]( https://doi.org/10.1136/bmj.38488.385995.8F )).

1. Le seuil de 0.05 est arbitraire.

----


----

#### Attention au *p-hacking*

Le *p-hacking* (ou *data dredging*) consiste √† manipuler les donn√©es et les mod√®les pour faire en sorte d'obtenir des *p-values* favorables √† l'hypoth√®se test√©e et, √©ventuellement, aux conclusions recherch√©es. **√Ä √©viter dans tous les cas. Toujours. Toujours. Toujours.**

Vid√©o sugg√©r√©e (en anglais).

[![p-hacking](images/05_p-hacking.png)](https://youtu.be/0Rnq1NpHdmw)

----

### Test de Wilcoxon √† un seul √©chantillon

Le _test de t_ suppose que la distribution des donn√©es est normale ... ce qui est rarement le cas, surtout lorsque les √©chantillons sont peu nombreux. Le test de Wilcoxon ne demande aucune supposition sur la distribution : c'est un [test non-param√©trique](https://help.xlstat.com/s/article/quelle-est-la-difference-entre-un-test-parametrique-et-un-test-non-parametrique?language=fr) bas√© sur le tri des valeurs.

```{r}
wilcox.test(x, mu = 18)
```

Le `V` est la somme des rangs positifs. Dans ce cas, la *p-value* est semblable √† celle du test de t, et les m√™mes conclusions s'appliquent.

### Tests de t √† deux √©chantillons

Les tests √† un √©chantillon servent plut√¥t √† s'exercer: rarement en aura-t-on besoin en recherche, o√π plus souvent, on voudra comparer les moyennes de deux unit√©s exp√©rimentales. L'exp√©rience comprend donc deux s√©ries de donn√©es continues, $x_1$ et $x_2$, issus de lois de distribution normale $\mathcal{N} \left( \mu_1, \sigma_1^2 \right)$ et $\mathcal{N} \left( \mu_2, \sigma_2^2 \right)$, et nous testons l'hypoth√®se nulle que $\mu_1 = \mu_2$. La statistique t est calcul√©e comme suit.

$$t = \frac{\bar{x_1} - \bar{x_2}}{ESDM}$$

L'ESDM est l'erreur standard de la diff√©rence des moyennes:

$$ESDM = \sqrt{ESM_1^2 + ESM_2^2}$$

Si vous supposez que les variances sont identiques, l'erreur standard (s) est calcul√©e pour les √©chantillons des deux groupes, puis ins√©r√©e dans le calcul des ESM. La statistique t sera alors √©valu√©e √† $n_1 + n_2 - 2$ degr√©s de libert√©. Si vous supposez que la variance est diff√©rente (*proc√©dure de Welch*), vous calculez les ESM avec les erreurs standards respectives, et la statistique t devient une approximation de la distribution de t avec un nombre de degr√©s de libert√© calcul√© √† partir des erreurs standards et du nombre d'√©chantillon dans les groupes: cette proc√©dure est consid√©r√©e comme plus prudente ([Dalgaard, 2008](https://www.springer.com/us/book/9780387790534), page 101).

Prenons les donn√©es d'iris pour l'exemple en excluant l'iris setosa √©tant donn√©e que les tests de t se restreignent √† deux groupes. Nous allons tester la longueur des p√©tales.

```{r}
iris_pl <- iris %>% 
    filter(Species != "setosa") %>%
    select(Species, Petal.Length)
sample_n(iris_pl, 5)
```

Dans la prochaine cellule, nous introduisons l'*interface-formule* de R, o√π l'on retrouve typiquement le `~`, entre les variables de sortie √† gauche et les variables d'entr√©e √† droite. Dans notre cas, la variable de sortie est la variable test√©e, `Petal.Length`, qui varie en fonction du groupe `Species`, qui est la variable d'entr√©e (variable explicative) - nous verrons les types de variables plus en d√©tails dans la section [Les mod√®les statistiques](#Les-mod%C3%A8les-statistiques), plus bas.

```{r}
t.test(formula = Petal.Length ~ Species,
       data = iris_pl, var.equal = FALSE)
```

Nous obtenons une sortie similaire aux pr√©c√©dentes. L'intervalle de confiance √† 95% exclu le z√©ro, ce qui est coh√©rent avec la p-value tr√®s faible, qui nous indique le rejet de l'hypoth√®se nulle au seuil 0.05. Les groupes ont donc des moyennes de longueurs de p√©tale significativement diff√©rentes.

----

### Enregistrer les r√©sultats d'un test

Il est possible d'enregistrer un test dans un objet.

```{r}
tt_pl <- t.test(formula = Petal.Length ~ Species,
                data = iris_pl, var.equal = FALSE)
summary(tt_pl)
str(tt_pl)
```

----

### Comparaison des variances

Pour comparer les variances, on a recours au test de F (F pour Fisher).

```{r}
var.test(formula = Petal.Length ~ Species,
         data = iris_pl)
```

Il semble que l'on pourrait relancer le test de *t* sans la proc√©dure Welch, avec `var.equal = TRUE`.

### Tests de Wilcoxon √† deux √©chantillons

Cela ressemble au test de t!

```{r}
wilcox.test(formula = Petal.Length ~ Species,
       data = iris_pl, var.equal = TRUE)
```

### Les tests pair√©s

Les tests pair√©s sont utilis√©s lorsque deux √©chantillons proviennent d'une m√™me unit√© exp√©rimentale: il s'agit en fait de tests sur la diff√©rence entre deux observations.

```{r}
set.seed(2555)

n <- 20
avant <- rnorm(n, 16, 4)
apres <- rnorm(n, 18, 3)
```

Il est important de sp√©cifier que le test est pair√©, la valeur par d√©faut de `paired` √©tant `FALSE`.

```{r}
t.test(avant, apres, paired = TRUE)
```

L'hypoth√®se nulle qu'il n'y ait pas de diff√©rence entre l'avant et l'apr√®s traitement est accept√©e au seuil 0.05.

**Exercice**. Effectuer un test de Wilcoxon pair√©.

## L'analyse de variance

L'analyse de variance consiste √† comparer des moyennes de plusieurs groupe distribu√©s normalement et de m√™me variance. Cette section sera √©labor√©e prochainement plus en profondeur. Consid√©rons-la pour le moment comme une r√©gression sur une variable cat√©gorielle.

```{r}
pl_aov <- aov(Petal.Length ~ Species, iris)
summary(pl_aov)
```

La prochaine section, justement, est vou√©e aux mod√®les statistiques explicatifs, qui incluent la r√©gression.

