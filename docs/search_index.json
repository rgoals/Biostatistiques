[["chapitre-anastatmv.html", "Chapitre 9 Analyse statistique multivariée 9.1 Introduction 9.2 Ordination non contraignante 9.3 Ordination contraignante", " Chapitre 9 Analyse statistique multivariée 9.1 Introduction Les méthodes multivariées constituent un ensemble doutils statistiques permettant aux utilisateurs de tirer le maximum dinformation contenu dans les tableaux à plusieurs variables. Dans létude avec plusieurs unités déchantillonnage et plusieurs variables (ex. abondance de plusieurs espèces dans plusieurs placeaux, plusieurs descripteurs quantitatifs et/ou qualitatifs mesurés sur plusieurs graines/fruits/arbres, etc.), lapport des méthodes statistiques multivariées est déterminant. Elles visent à structurer et simplifier les données issues de plusieurs variables, sans privilégier lune dentre elles en particulier. Le choix dune méthode dépend de lobjectif initial, des types de variables manipulées mais aussi, de la forme des résultats à obtenir. Il existe différents groupes de méthodes multivariées. Nous présentons ici, les méthodes dordination (ce chapitre) et les méthodes de classification (chapitre suivant) qui font partie des méthodes multivariées couramment utilisées. En écologie, biologie, agronommie comme en foresterie, la plupart des tableaux de données comprennent de nombreuses variables : pH, teneurs en nutriments (N, P, K, Mg, Ca, ), variables du climat (pluviométrie, température, SDI, ), espèces ou cultivars et leurs paramètres végétatifs et de rendements, topographie, etc. Lordination vise à mettre de lordre dans de telles données dont le nombre élevé de variables peut amener à des difficultés dappréciation et dinterprétaion (Legendre et Legendre, 2012).  Explicitement, le terme ordination est utilisé en écologie pour désigner les techniques de réduction daxe. Ces techniques permettent de dégager linformation la plus importante en projetant une synthèse des relations entre les observations et entre les variables. Certaines techniques ne supposant aucune structure a priori sont dites non-contraignantes : elles ne comprennent pas de tests statistiques. À linverse, les ordinations contraignantes lient des variables descriptives avec une ou plusieurs variables prédictives. La référence en la matière est indiscutablement le livre Numerical Ecology de Legendre et Legendre (2012). Lanalyse en composantes principales est probablement la plus connue de ces techniques. Mais de nombreuses autres techniques ont été développées au cours des dernières années, chacune ayant ses domaines dapplication. Cette section en couvrira quelques unes et vous guidera vers la technique la plus appropriée pour vos données.  Objectifs spécifiques: À la fin de ce chapitre, vous serez en mesure deffectuer des calculs dordination à laide des techniques communes de réduction daxes entre autres : lAnalyse en Composantes Principales (ACP) - Principal Components Analysis (PCA), lAnalyse de Correspondance (AC) - Correspondence Analysis (CA), encore AFC avec variantes AFCS, AFCM ? lAnalyse en Coordonnées Principales (ACoP) - Principal Coordinates Analysis (PCoA), variante du PoMd, lAnalyse Discriminante Linéaire (ADL) - Linear Discriminant Analysis (LDA), lAnalyse de Redondance (RDA) - Redundancy Analysis (RDA), et lAnalyse canonique des correspondances (ACC) - Canonical Correspondence Analysis (CCA), variante AC sous contrainte ? 9.2 Ordination non contraignante Cette section couvrira : lanalyse en composantes principales (ACP), lanalyse de correspondance (AC), lanalyse factorielle (AF), ainsi que lanalyse en coordonnées principales (ACoP). Méthode Distance préservée Variables (type de données) Analyse en composantes principales (ACP) Distance euclidienne Données quantitatives, relations linéaires (attention aux double-zéros) Analyse de correspondance (AC) Distance de \\(\\chi^2\\) Données non-négatives, dimensionnellement homogènes ou binaires, abondance ou occurence Positionnement multidimensionnel (PoMd) Toute mesure de dissimilarité Données quantitatives, qualitatives nominales/ordinales ou mixtes Source: Adapté de (Legendre et Legendre, 2012, chapitre 9) 9.2.1 Analyse en composantes principales 9.2.1.1 Description Lobjectif dune ACP est de représenter les données dans un nombre réduit de dimensions représentant le plus possible la variation dun tableau de données : elle permet de projetter les données dans un espace où les variables sont combinées en axes orthogonaux dont le premier axe capte le maximum de variance. LACP peut par exemple être utilisée pour analyser des corrélations entre variables ou dégager linformation la plus pertinente dun tableau de données météo ou de signal en un nombre plus retreint de variables.  LACP effectue une rotation des axes à partir du centre (moyenne) du nuage de points effectuée de manière à ce que le premier axe définisse la direction où lon retrouve la variance maximale. Ce premier axe est une combinaison linéaire des variables et forme la première composante principale. Une fois cet axe définit, on trouve le deuxième axe, orthogonal au premier, où lon retouve la variance maximale - cet axe forme la deuxième composante principale, et ainsi de suite jusquà ce que le nombre daxe corresponde au nombre de variables. Conceptuellement, toutes les colonnes dun jeu de données contiennent de linformation potentiellement interessante. LACP crée un jeu de données artificiel avec un nombre de dimensions égal à celui du premier. La seule différence est que ses premières dimensions concentrent la majeure partie de linformation. Dans le monde de lACP, linformation est appelée inertie. Les dimensions sont appelées facteurs ou axes principaux. Les projections des observations sur ces axes principaux sont appelés les scores ou valeurs propres (eigenvalues). Les projections des variables sur les axes principaux sont les vecteurs propres (eigenvectors, ou loadings). La variance des composantes principales diminue de la première à la dernière, et peut être calculée comme une proportion de la variance totale : cest le pourcentage dinertie. Par convention, on utilise les valeurs propres (eigenvalues) pour mesurer limportance des axes. Si la première composante principale a une inertie de 50% et la deuxième une intertie de 30%, la représentation en \\(2D\\) des projections représentera 80% de la variance du nuage de points. Linformation perdue est donc de 20% sur les dimensions initiales réduites à 2 dimensions. Lhétérogénéité des échelles de mesure peut avoir une grande importance sur les résultats dune ACP (les données doivent être dimensionnellement homogènes). En effet, la hauteur dun cériser aura une variance plus grande que le diamètre dune cérise exprimé dans les mêmes unités, et cette dernière aura plus de variance que la teneur en cuivre dune feuille. Il est conséquemment avisé de mettre les données à léchelle en centrant la moyenne à \\(0\\) et lécart-type à \\(1\\) avant de procéder à une ACP. LACP a été conçue pour projetter en un nombre moindre de dimensions des observations dont les distributions sont multinormales. Bien que lACP soit une technique robuste, il est préférable de transformer préalablement les variables dont la distribution est particulièrement asymétriques (Legendre et Legendre, 2012, p. 450). Le cas échéant, les valeurs extrêmes pourraient faire dévier les vecteurs propres et biaiser lanalyse. En particulier, les ACP menées sur des données compositionnelles sont réputées pour générer des analyses biaisées (Pawlowsky-Glahn and Egozcue, 2006). Le test de Mardia (Korkmaz, 2014) peut être utilisé pour tester la multinormalité. Une distribution multinormale devrait générer des scores en forme dhypersphère (en forme de cercle sur un biplot : voir plus loin). 9.2.1.2 Vecteurs propres et valeurs propres Lalgorithme de lACP effectue sur la matrice individus/variables, différentes opérations, centrage-réduction des données, diagonalisation de la matrice de corrélation, extraction de valeurs propres et de vecteurs propres, etc. en vue de passer du nombre de variables initiales à un nombre réduit de variables obtenues par combinaison linéaire des premières :les composantes principales (Kakai et al., 2016). Une matrice carrée (comme une matrice de covariance, appelée \\(\\Sigma\\)) multipliée par un vecteur propre (\\(e\\)) est égale aux valeurs propres (\\(\\lambda\\)) multipliées par les vecteurs propres (\\(e\\)). \\[ \\Sigma e = \\lambda e \\] De manière intuitive, les vecteurs propres indiquent lorientation de la covariance, et les valeurs propres indiquent la longueur associée à cette direction. LACP est basée sur le calcul des vecteurs propres et des valeurs propres de la matrice de covariance des variables. Pour dabord obtenir les valeurs propres (\\(\\lambda\\)), il faut résoudre léquation \\[ det(cov(X) - \\lambda I) = 0 \\] où \\(det()\\) est lopération permettant de calculer le déterminant, \\(cov()\\) est lopération pour calculer la covariance, \\(X\\) est la matrice de données (le dataframe), les \\(\\lambda\\) sont les valeurs propres et \\(I\\) est une matrice didentité. Pour \\(p\\) variables dans votre tableau \\(X\\), vous obtiendrez \\(p\\) valeurs propres. Ensuite, on trouve les vecteurs propres en résolvant léquation $ e = e $. Bien quil soit possible deffectuer cette opération à la main pour des cas très simples, vous aurez avantage à utiliser un langage de programmation. Chargeons les données diris, puis isolons seulement les deux dimensions des sépales de lespèce setosa. library(&quot;tidyverse&quot;) ## -- Attaching packages --------------------------------------- tidyverse 1.3.1 -- ## v ggplot2 3.3.3 v purrr 0.3.4 ## v tibble 3.1.1 v dplyr 1.0.5 ## v tidyr 1.1.3 v stringr 1.4.0 ## v readr 1.4.0 v forcats 0.5.1 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() data(&quot;iris&quot;) setosa_sepal &lt;- iris %&gt;% filter(Species == &quot;setosa&quot;) %&gt;% select(starts_with(&quot;Sepal&quot;)) %&gt;% rename( long_sepal = Sepal.Length, larg_sepal = Sepal.Width) setosa_sepal ## long_sepal larg_sepal ## 1 5.1 3.5 ## 2 4.9 3.0 ## 3 4.7 3.2 ## 4 4.6 3.1 ## 5 5.0 3.6 ## 6 5.4 3.9 ## 7 4.6 3.4 ## 8 5.0 3.4 ## 9 4.4 2.9 ## 10 4.9 3.1 ## 11 5.4 3.7 ## 12 4.8 3.4 ## 13 4.8 3.0 ## 14 4.3 3.0 ## 15 5.8 4.0 ## 16 5.7 4.4 ## 17 5.4 3.9 ## 18 5.1 3.5 ## 19 5.7 3.8 ## 20 5.1 3.8 ## 21 5.4 3.4 ## 22 5.1 3.7 ## 23 4.6 3.6 ## 24 5.1 3.3 ## 25 4.8 3.4 ## 26 5.0 3.0 ## 27 5.0 3.4 ## 28 5.2 3.5 ## 29 5.2 3.4 ## 30 4.7 3.2 ## 31 4.8 3.1 ## 32 5.4 3.4 ## 33 5.2 4.1 ## 34 5.5 4.2 ## 35 4.9 3.1 ## 36 5.0 3.2 ## 37 5.5 3.5 ## 38 4.9 3.6 ## 39 4.4 3.0 ## 40 5.1 3.4 ## 41 5.0 3.5 ## 42 4.5 2.3 ## 43 4.4 3.2 ## 44 5.0 3.5 ## 45 5.1 3.8 ## 46 4.8 3.0 ## 47 5.1 3.8 ## 48 4.6 3.2 ## 49 5.3 3.7 ## 50 5.0 3.3 Test de multinormalité de Mardia : library(&quot;MVN&quot;) ## Registered S3 method overwritten by &#39;GGally&#39;: ## method from ## +.gg ggplot2 ## sROC 0.1-2 loaded setosa_sepal_mvn &lt;- mvn(setosa_sepal, mvnTest = &quot;mardia&quot;) setosa_sepal_mvn$multivariateNormality ## Test Statistic p value Result ## 1 Mardia Skewness 0.759503524380438 0.943793240544741 YES ## 2 Mardia Kurtosis 0.0934600553610254 0.925538081956867 YES ## 3 MVN &lt;NA&gt; &lt;NA&gt; YES H0 du test : La distribution nest pas multinormale. Pour considérer la distribution comme multinormale, les p-value de la distortion (Mardia Skewness) et de la statistique de Kurtosis (Mardia Kurtosis) doivent être égales ou plus élevées que \\(0.05\\) (Kormaz, 2019, fiche daide de la fonction mvn de R). Cest bien le cas pour les données du tableau setosa_sepal. Pour des petits jeux de données, on pourra faire certains calculs à la main. Lidée majeure dans ce cas est de savoir techniquement comment ça se fait. Pour rappels les calculs à la mitaine : de la moyenne, \\[ \\bar{x} = \\frac{1}{N} \\sum_{i=1}^{n} n_{i} x_{i} \\] de la variance, \\[ Var(X) =\\frac{1}{N} \\sum_{i=1}^{n} n_{i}\\left(\\bar{x}-x_{i}\\right)^{2} \\] de lécart-type, \\[ \\sigma_{X}=\\sqrt{\\operatorname{Var}(x)} \\] de la covariance, avec une 2nde formule de calcule plus pratique \\[ \\operatorname{Cov}(X, Y)=\\frac{1}{N} \\sum\\left(x_{i}-\\mu(X)\\right) \\times\\left(y_{i}-\\mu(Y)\\right) \\] \\[ \\operatorname{Cov}(X, Y)=\\left(\\frac{1}{N} \\sum x_{i} y_{i}\\right)-\\mu(X) \\times \\mu(Y) \\] du coefficient de corrélation \\[ \\operatorname{Corr}(X, Y)=\\frac{\\operatorname{Cov}(X, Y)}{\\sigma(X) \\sigma(Y)} \\] Mais profitons du génie logiciel avec R. Retirons de la matrice de covariance, les valeurs et vecteurs propres avec la fonction eigen du package base. setosa_eigen &lt;- eigen(cov(setosa_sepal)) setosa_eigenval &lt;- setosa_eigen$values setosa_eigenval ## [1] 0.23366074 0.03427804 setosa_eigenvec &lt;- setosa_eigen$vectors setosa_eigenvec ## [,1] [,2] ## [1,] 0.6717496 -0.7407783 ## [2,] 0.7407783 0.6717496 Le premier vecteur propre correspond à la première colonne, et le second à la deuxième. Les coordonnées \\(x\\) et \\(y\\) sont les premières et deuxièmes lignes. Les vecteurs propres ont une longueur unitaire (norme de 1). Ils peuvent être mis à léchelle à la racine carrée des valeurs propres. setosa_eigenvec_sc &lt;- setosa_eigenvec %*% diag(sqrt(setosa_eigen$values)) setosa_eigenvec_sc ## [,1] [,2] ## [1,] 0.3247134 -0.1371501 ## [2,] 0.3580809 0.1243699 Un aperçu de la racine carrée des valeurs propres en matrice diagonale : diag(sqrt(setosa_eigen$values)) ## [,1] [,2] ## [1,] 0.4833847 0.0000000 ## [2,] 0.0000000 0.1851433 Pour effectuer la translation des vecteurs propres au centre du nuage de point, nous avons besoin du centroïde. centroid &lt;- setosa_sepal %&gt;% apply(., 2, mean) centroid ## long_sepal larg_sepal ## 5.006 3.428 Aperçu graphique : Le nuage de points plot(setosa_sepal, asp = 1) # asp, the y/x aspect ratio Ajout des vecteurs propres brutes en couleur verte : plot(setosa_sepal, asp = 1) # asp, the y/x aspect ratio # vecteurs propres brutes lines(x = c(centroid[1], centroid[1] + setosa_eigenvec[1, 1]), y = c(centroid[2], centroid[2] + setosa_eigenvec[2, 1]), col = &quot;green&quot;, lwd = 3) # vecteur propre 1 lines(x=c(centroid[1], centroid[1] + setosa_eigenvec[1, 2]), y=c(centroid[2], centroid[2] + setosa_eigenvec[2, 2]), col = &quot;green&quot;, lwd = 3) # vecteur propre 2 Ajout des vecteurs propres à léchelle en couleur rouge : plot(setosa_sepal, asp = 1) # asp, the y/x aspect ratio # vecteurs propres brutes lines(x = c(centroid[1], centroid[1] + setosa_eigenvec[1, 1]), y = c(centroid[2], centroid[2] + setosa_eigenvec[2, 1]), col = &quot;green&quot;, lwd = 3) # vecteur propre 1 lines(x=c(centroid[1], centroid[1] + setosa_eigenvec[1, 2]), y=c(centroid[2], centroid[2] + setosa_eigenvec[2, 2]), col = &quot;green&quot;, lwd = 3) # vecteur propre 2 # vecteurs propres à l&#39;échelle lines(x = c(centroid[1], centroid[1] + setosa_eigenvec_sc[1, 1]), y = c(centroid[2], centroid[2] + setosa_eigenvec_sc[2, 1]), col = &quot;red&quot;, lwd = 4) # vecteur propre 1 lines(x = c(centroid[1], centroid[1] + setosa_eigenvec_sc[1, 2]), y = c(centroid[2], centroid[2] + setosa_eigenvec_sc[2, 2]), col = &quot;red&quot;, lwd = 4) # vecteur propre 2 Ajout du centroid, le point bleu : plot(setosa_sepal, asp = 1) # asp, the y/x aspect ratio # vecteurs propres brutes lines(x = c(centroid[1], centroid[1] + setosa_eigenvec[1, 1]), y = c(centroid[2], centroid[2] + setosa_eigenvec[2, 1]), col = &quot;green&quot;, lwd = 3) # vecteur propre 1 lines(x=c(centroid[1], centroid[1] + setosa_eigenvec[1, 2]), y=c(centroid[2], centroid[2] + setosa_eigenvec[2, 2]), col = &quot;green&quot;, lwd = 3) # vecteur propre 2 # vecteurs propres à l&#39;échelle lines(x = c(centroid[1], centroid[1] + setosa_eigenvec_sc[1, 1]), y = c(centroid[2], centroid[2] + setosa_eigenvec_sc[2, 1]), col = &quot;red&quot;, lwd = 4) # vecteur propre 1 lines(x = c(centroid[1], centroid[1] + setosa_eigenvec_sc[1, 2]), y = c(centroid[2], centroid[2] + setosa_eigenvec_sc[2, 2]), col = &quot;red&quot;, lwd = 4) # vecteur propre 2 points(x = centroid[1], y = centroid[2], pch = 16, cex = 2, col = &quot;blue&quot;) # centroid On peut observer que, comme mentionné plus haut, les vecteurs propres indiquent lorientation de la covariance, et les valeurs propres indiquent la longueur associée à cette direction. 9.2.1.3 Biplot de lACP Imaginez un nuage de points en \\(3D\\), axe \\(y\\) compris. Vous tournez votre nuage de points pour trouver la perspective en \\(2D\\) qui fera en sorte que vos données soient les plus dispersées possibles, voir présentation grossière : Nuage de points en 3 dimensions Lorsque la perspective est trouvée, avec une lampe de poche, vous illuminez votre nuage de points dans laxe de cette perspective : vous venez deffectuer une analyse en composantes principales, et lombre des points et des axes sur le mur formera votre biplot. Pour créer un biplot, on juxtapose : les descripteurs (les variables) en tant que vecteurs propres, représentés par des flèches, et les objets (les observations) en tant que scores (valeurs propres), représentés par des points. Les résultats dune ordination peuvent être présentés selon deux types de biplots ou de projections (Legendre et Legendre, 2012) courramment utilisés : Les Biplots de distance Ce type de projection permet de visualiser la position des objets (observations) entre eux et par rapport aux descripteurs (variables) et dapprécier la contribution des descripteurs pour créer les composantes principales. Pour créer un biplot de distance, on projette directement les vecteurs propres (\\(U\\)) en guise de descripteurs. Pour ce qui est des objets, on utilise les scores de lACP (\\(F\\)). De cette manière, les distances euclidiennes entre les scores sont des approximations des distances euclidiennes dans lespace multidimentionnel, la projection dun objet sur un descripteur perpendiculairement à ce dernier est une approximation de la position de lobjet sur le descripteur et la projection dun descripteur sur un axe principal est proportionnelle à sa contribution pour générer laxe. Les Biplots de corrélation Cette projection permet dapprécier les corrélations entre les descripteurs. Pour ce faire, les objets et les valeurs propres doivent être transformés. Pour générer les descripteurs, les vecteurs propres (\\(U\\)) doivent être multipliés par la matrice diagonalisée de la racine carrée des valeurs propres (\\(\\Lambda\\)), cest-à-dire \\(U \\Lambda ^{\\frac{1}{2}}\\). En ce qui a trait aux objets, on multiplie les scores (\\(F\\)) par la racine carrée négative des valeurs propres diagonalisées, cest-à-dire \\(F \\Lambda ^{- \\frac{1}{2}}\\). De cette manière, tout comme cest le cas pour le biplot de distance, la projection dun objet sur un descripteur perpendiculairement à ce dernier est une approximation de la position de lobjet sur le descripteur, la projection dun descripteur sur un axe principal est proportionnelle à son écart-type et les angles entre les descripteurs sont proportionnels à leur corrélation (et non pas leur proximité). En dautres mots, le biplot de distances devrait être utilisé pour apprécier la distance entre les objets et le biplot de corrélation devrait être utilisé pour apprécier les corrélations entre les descripteurs. Mais dans tous les cas, le type de biplot utilisé doit être indiqué. Biplot de corrélation permettant de visualiser les corrélations entre des variables météorologiques. Source: Parent, 2017 Le triplot est une forme apparentée au biplot, auquel on ajoute des variables prédictives. Le triplot est utile pour représenter les résultats des ordinations contraignantes comme les analyses de redondance et les analyse de correspondance canoniques. 9.2.1.4 Application Bien que lACP puisse être effectuée grâce à des modules de base de R, nous utiliserons le module vegan. Le tableau varechem comprend des données issues danalyse de sols identifiés par leur composition chimique, leur pH, leur profondeur totale et la profondeur de lhumus publiées dans Väre et al. (1995) et exportées du module vegan. library(&quot;vegan&quot;) ## Loading required package: permute ## Loading required package: lattice ## This is vegan 2.5-7 data(&quot;varechem&quot;) varechem %&gt;% sample_n(5) ## N P K Ca Mg S Al Fe Mn Zn Mo Baresoil Humdepth ## 2 22.3 47.4 165.9 436.1 64.3 42.3 316.5 200.1 28.2 7.2 0.3 0.01 1.5 ## 12 16.0 32.7 126.4 471.4 61.3 31.1 108.8 9.5 26.4 6.0 0.4 11.20 2.2 ## 22 26.6 36.7 171.4 738.6 94.9 33.8 20.7 2.5 77.6 7.4 0.3 23.00 2.8 ## 18 19.8 42.1 139.9 519.4 90.0 32.3 39.0 40.9 58.1 4.5 0.3 43.90 2.2 ## 4 18.0 64.9 224.5 517.6 59.7 52.9 435.1 101.2 38.0 9.5 1.1 21.30 1.8 ## pH ## 2 2.9 ## 12 2.9 ## 22 2.8 ## 18 2.7 ## 4 2.9 Comme nous lavons vu précdemment, les données de concentration sont de type compositionnelles. Les données compositionnelles du tableau varechem mériteraient dêtre transformées (Aitchison et Greenacre, 2002). Utilisons les log-ratios centrés (clr). library(&quot;compositions&quot;) ## Welcome to compositions, a package for compositional data analysis. ## Find an intro with &quot;? compositions&quot; ## ## Attaching package: &#39;compositions&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## cor, cov, dist, var ## The following objects are masked from &#39;package:base&#39;: ## ## %*%, norm, scale, scale.default varecomp &lt;- varechem %&gt;% select(-Baresoil, -Humdepth, -pH) %&gt;% mutate(Fv = apply(., 1, function(x) 1e6 - sum(x))) vareclr &lt;- varecomp %&gt;% acomp(.) %&gt;% clr(.) %&gt;% as_tibble() %&gt;% bind_cols(varechem %&gt;% select(Baresoil, Humdepth, pH)) vareclr %&gt;% sample_n(5) ## # A tibble: 5 x 15 ## N P K Ca Mg S Al Fe Mn Zn Mo ## * &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -1.76 -0.553 0.565 2.11 0.575 -0.706 0.159 -1.20 -1.30 -1.95 -4.99 ## 2 -0.271 -0.648 0.00500 1.71 -0.524 -1.07 -0.106 -1.64 -0.482 -1.64 -5.38 ## 3 -0.881 -0.648 0.723 2.26 0.384 -0.825 -0.347 -2.15 -0.611 -2.26 -5.53 ## 4 -1.69 -0.624 0.830 1.59 -0.0312 -0.729 0.189 -0.626 -0.331 -2.60 -5.49 ## 5 -0.901 0.00174 1.27 2.32 0.361 -0.546 -1.41 -3.42 0.374 -2.07 -5.50 ## # ... with 4 more variables: Fv &lt;dbl&gt;, Baresoil &lt;dbl&gt;, Humdepth &lt;dbl&gt;, pH &lt;dbl&gt; Effectuons lACP. Pour cet exemple, nous standardiserons les données étant données que les colonnes Baresoil, Humedepth et pH ne sont pas à la même échelle que les colonnes des clr. vareclr_sc &lt;- scale(vareclr) vare_pca &lt;- rda(vareclr_sc) # ou bien rda(vareclr, scale = TRUE, mais la mise à l&#39;échelle préalable est plus explicite) Lobjet vareclr_pca contient linformation nécessaire pour mener notre ACP. summary(vare_pca, scaling = 2) ## ## Call: ## rda(X = vareclr_sc) ## ## Partitioning of variance: ## Inertia Proportion ## Total 15 1 ## Unconstrained 15 1 ## ## Eigenvalues, and their contribution to the variance ## ## Importance of components: ## PC1 PC2 PC3 PC4 PC5 PC6 PC7 ## Eigenvalue 7.1523 2.4763 2.1122 0.93015 0.57977 0.48786 0.36646 ## Proportion Explained 0.4768 0.1651 0.1408 0.06201 0.03865 0.03252 0.02443 ## Cumulative Proportion 0.4768 0.6419 0.7827 0.84473 0.88338 0.91590 0.94034 ## PC8 PC9 PC10 PC11 PC12 PC13 ## Eigenvalue 0.29432 0.19686 0.15434 0.107357 0.095635 0.042245 ## Proportion Explained 0.01962 0.01312 0.01029 0.007157 0.006376 0.002816 ## Cumulative Proportion 0.95996 0.97308 0.98337 0.990527 0.996902 0.999719 ## PC14 ## Eigenvalue 0.0042200 ## Proportion Explained 0.0002813 ## Cumulative Proportion 1.0000000 ## ## Scaling 2 for species and site scores ## * Species are scaled proportional to eigenvalues ## * Sites are unscaled: weighted dispersion equal on all dimensions ## * General scaling constant of scores: 4.309777 ## ## ## Species scores ## ## PC1 PC2 PC3 PC4 PC5 PC6 ## N 0.1437 0.7606 -0.6792 0.19837 0.1128526 -0.050149 ## P 0.8670 -0.3214 -0.2950 -0.22940 0.1437960 -0.042884 ## K 0.9122 -0.3857 0.2357 0.03469 0.2737020 0.075717 ## Ca 0.9649 -0.3362 -0.2147 0.17757 -0.2188717 0.008051 ## Mg 0.8263 -0.2723 0.1035 0.52135 -0.1495399 -0.342214 ## S 0.8825 -0.3169 0.3539 -0.21216 0.1176279 -0.191386 ## Al -1.0105 -0.2442 0.2146 0.02674 -0.1005560 -0.043569 ## Fe -1.0338 -0.2464 0.1492 0.13162 0.1512218 0.081571 ## Mn 0.9556 0.1041 -0.1256 -0.21300 0.2565831 0.275275 ## Zn 0.7763 -0.1031 -0.3123 -0.36493 -0.5665691 0.153089 ## Mo -0.2152 0.8717 0.4065 -0.33643 -0.2134335 -0.167725 ## Fv 0.2360 0.5776 -0.8112 0.12736 0.1280097 -0.109737 ## Baresoil 0.5147 0.4210 0.4472 0.54980 -0.1438570 0.463148 ## Humdepth 0.7455 0.4379 0.5194 0.16493 0.0004757 -0.273056 ## pH -0.5754 -0.5864 -0.5957 0.23408 -0.1517661 -0.056641 ## ## ## Site scores (weighted sums of species scores) ## ## PC1 PC2 PC3 PC4 PC5 PC6 ## 18 0.16862 0.423777 0.46731 0.91175 1.10380 1.06421 ## 15 -0.09705 -0.097482 0.61143 -0.29049 1.14916 0.40622 ## 24 0.02831 -0.795737 0.74176 -0.19097 -2.43337 -0.81762 ## 27 1.39081 -0.354376 -0.19377 -0.45160 0.46020 -0.31446 ## 23 1.30346 0.357866 0.29887 0.76856 0.20913 -0.64145 ## 19 0.43636 0.495037 1.21722 1.18128 -0.98242 -0.74474 ## 22 1.07306 0.467575 -0.32245 0.03717 0.13956 -0.64972 ## 16 0.02545 0.659714 -0.28861 -0.01424 0.47105 0.45173 ## 28 1.42005 0.007356 -0.29000 -0.78474 0.97592 -0.80263 ## 13 -0.50638 -0.220909 1.52981 0.26289 0.42135 0.94054 ## 14 0.45392 0.649297 0.44573 -0.26620 -0.74522 -0.53228 ## 20 0.18623 0.259640 0.89112 0.21096 -0.51393 2.24361 ## 25 1.26264 0.225744 -0.96668 -0.69334 0.61990 0.43312 ## 7 -1.48685 0.739545 -0.20926 1.09256 0.61856 -0.87999 ## 5 -0.50622 1.108685 -2.61287 -1.00433 -1.35383 1.21964 ## 6 -1.28653 0.898663 -0.38778 -0.47556 -0.02449 -0.29419 ## 3 -1.72773 0.476962 -0.48878 0.71156 1.06398 -1.33473 ## 4 -0.82844 -0.296515 1.20315 -1.49821 -0.18330 1.05231 ## 2 -1.00247 -0.609253 0.25185 -0.85420 0.71031 0.14854 ## 9 -0.43405 -0.338912 0.55348 -1.35776 -0.81986 -1.02468 ## 12 -0.05083 0.122645 -0.04611 -0.56047 -0.26151 -0.98053 ## 10 0.17891 -2.315489 -0.69084 -0.19547 0.80628 0.04291 ## 11 -0.46443 -2.592018 -1.21615 1.56359 -0.62334 0.28748 ## 21 0.46316 0.728185 -0.49843 1.89726 -0.80791 0.72671 # scaling = 2 pour obtenir les infos pour les biplots de corrélation La deuxième ligne de Importance of components, Proportion Explained, indique la proportion de la variance totale captée successivement par les axes principaux. Le premier axe principal comporte 47.68% de la variance. Le deuxième axe principal ajoutant une proportion de 16,51%, une représentation en deux axes principaux présentent 64.19 % de la variance. prop_expl &lt;- vare_pca$CA$eig / sum(vare_pca$CA$eig) prop_expl ## PC1 PC2 PC3 PC4 PC5 PC6 ## 0.4768180610 0.1650859388 0.1408156459 0.0620101490 0.0386511040 0.0325238535 ## PC7 PC8 PC9 PC10 PC11 PC12 ## 0.0244303815 0.0196215021 0.0131238464 0.0102890284 0.0071571089 0.0063756951 ## PC13 PC14 ## 0.0028163495 0.0002813359 La décision du nombre daxes principaux à retenir est arbitraire. Elle peut dépendre dun nombre maximal de paramètres à retenir pour éviter de surdimensionner un modèle (curse of dimensionality, section 11), ou dun seuil de pourcentage de variance minimale à retenir, par exemple 75%, ou bien, vous retiendrez deux composantes principales si vous désirez présenter un seul biplot. Lapproche de Kaiser-Guttmann (Borcard et al., 2011) consiste à sélectionner les composantes principales dont la valeur propre est supérieure à leur moyenne. plot(x = 1:length(vare_pca$CA$eig), y = vare_pca$CA$eig, type = &quot;b&quot;, xlab = &quot;Rang de la valeur propre&quot;, ylab = &quot;Valeur propre&quot;) abline(h = mean(vare_pca$CA$eig), col = &quot;red&quot;, lty = 2) Lapproche du broken stick consiste à couper un bâton dune longueur de 1 en n tranches : La première tranche est de longueur \\(\\frac{1}{n}\\). La tranche suivante est dune longueur de la tranche précédente à laquelle on aditionne \\(\\frac{1}{longueur~restante}\\). Puis on place les longueurs en ordre décroissant. On retient les composantes principales dont les valeurs propres cumulées sont plus grandes que le broken stick. broken_stick &lt;- function(x) { bsm &lt;- vector(&quot;numeric&quot;, length = x) bsm[1] &lt;- 1/x for (i in 2:x) { bsm[i] &lt;- bsm[i-1] + 1/(x+1-i) } bsm &lt;- rev(bsm/x) return(bsm) } Le graphique du broken stick : plot(x = 1:length(vare_pca$CA$eig), y = prop_expl, type = &quot;b&quot;, xlab = &quot;Rang de la valeur propre&quot;, ylab = &quot;Valeur propre&quot;) lines(x = 1:length(vare_pca$CA$eig), y = broken_stick(length(vare_pca$CA$eig)), col = &quot;red&quot;, lty = 2) Les approches Kaiser-Guttmann et broken stick suggèrent que les trois premières composantes sont suffisantes pour décrire la dispersion des données. Généralement, on estime quune concentration dinformation de 50 % du tableau de départ est suffisante pour garantir une précision danalyse et sert de critère de choix du nombre de composantes principales à retenir (Kakai et al., 2016). Examinons les loadings (vecteurs propres) plus en particulier. Dans le langage du module vegan, les vecteurs propres sont les espèces (species) et les scores sont les sites. vare_eigenvec &lt;- vegan::scores(vare_pca, scaling = 2, display = &quot;species&quot;, choices = 1:(ncol(vareclr)-1)) vare_eigenvec ## PC1 PC2 PC3 PC4 PC5 PC6 ## N 0.1437343 0.7606006 -0.6792046 0.1983670 0.1128526122 -0.050148980 ## P 0.8669892 -0.3213683 -0.2949864 -0.2294036 0.1437959857 -0.042883754 ## K 0.9122089 -0.3857245 0.2356904 0.0346904 0.2737019601 0.075717162 ## Ca 0.9648855 -0.3361651 -0.2147486 0.1775746 -0.2188716732 0.008050762 ## Mg 0.8263327 -0.2723055 0.1035276 0.5213484 -0.1495399242 -0.342213793 ## S 0.8824519 -0.3169039 0.3538854 -0.2121562 0.1176278503 -0.191386377 ## Al -1.0105173 -0.2441785 0.2145614 0.0267422 -0.1005559874 -0.043569364 ## Fe -1.0337676 -0.2463987 0.1491865 0.1316173 0.1512218115 0.081571443 ## Mn 0.9555632 0.1041030 -0.1256178 -0.2130047 0.2565830557 0.275275174 ## Zn 0.7763480 -0.1030878 -0.3122919 -0.3649341 -0.5665691228 0.153089144 ## Mo -0.2152399 0.8717229 0.4064967 -0.3364279 -0.2134335302 -0.167725160 ## Fv 0.2360040 0.5775863 -0.8111953 0.1273582 0.1280096553 -0.109737235 ## Baresoil 0.5147445 0.4209983 0.4472351 0.5497950 -0.1438569673 0.463148072 ## Humdepth 0.7455213 0.4379436 0.5193895 0.1649306 0.0004756685 -0.273056212 ## pH -0.5753858 -0.5863743 -0.5957495 0.2340826 -0.1517660977 -0.056640816 ## PC7 PC8 PC9 PC10 PC11 ## N -0.09111164 -0.06122008 0.315645453 0.08090232 -0.019251478 ## P 0.26894062 0.34111276 0.021124287 0.08756299 -0.045741546 ## K -0.21662612 -0.01641260 0.143099440 -0.08737113 0.183005607 ## Ca 0.03630015 0.04775616 -0.073609828 -0.10601799 0.161460554 ## Mg 0.04617838 -0.12098602 -0.051599273 0.18373857 -0.009862571 ## S -0.26825994 0.15822845 0.038378858 0.05100717 -0.138785063 ## Al -0.22737412 0.10598673 0.040586196 -0.14473132 -0.089462074 ## Fe 0.10553041 -0.09254655 -0.079426433 0.09908706 -0.006376211 ## Mn 0.20224538 -0.19347804 -0.038859808 -0.07637994 -0.083300112 ## Zn -0.12332232 -0.14862229 0.024026151 0.02643462 -0.064973307 ## Mo 0.13788948 0.17165900 0.032981311 0.01419924 0.128814989 ## Fv -0.20911147 0.11289753 -0.281443886 -0.08391004 -0.012456867 ## Baresoil -0.02103009 0.23028292 0.004554036 0.02604286 -0.061147847 ## Humdepth 0.17061078 -0.11310394 0.027515405 -0.23068827 -0.102189307 ## pH 0.19890884 0.12152266 0.150118818 -0.15240317 -0.037691048 ## PC12 PC13 PC14 ## N 0.045420621 0.05020956 0.002340519 ## P 0.145128883 -0.03337551 -0.010109130 ## K 0.002260341 -0.10566808 0.001169065 ## Ca 0.041210064 0.14341793 0.007419161 ## Mg -0.063493608 -0.03782662 -0.023575986 ## S -0.117144869 0.06075094 0.025874035 ## Al 0.058212507 0.01983102 -0.037901576 ## Fe 0.049837173 -0.01169516 0.036048221 ## Mn -0.133353213 0.02679781 -0.021373612 ## Zn 0.051057277 -0.06538348 0.010896560 ## Mo -0.114803631 -0.01989539 -0.001335923 ## Fv -0.020157331 -0.05448619 0.005707928 ## Baresoil -0.019696758 -0.01640490 0.003823725 ## Humdepth 0.109293684 -0.02485030 0.016559206 ## pH -0.153813168 -0.04523353 0.014193061 ## attr(,&quot;const&quot;) ## [1] 4.309777 Lordre dimportance des vecteurs propres est établi en ordre croissant des élément des vecteurs propres associées. Un vecteur propre est une combinaison linéaire des variables. Par exemple, le premier vecteur propre pointe surtout dans la direction du Fe (-1.497) et de lAl (-1.463). Le deuxième pointe surtout vers le Mo (2.145). Les vecteurs (loadings) dun biplot de distance présentant les deux premières composantes principales prendront les coordonnées des deux premières colonnes. Le vecteur Al aura la coordonnée [-1.463 ; -0.601], le vecteur de Fe sera placé à [-1.497 ; -0.606] et le vecteur Mo à [-0.312 ; 2.145]. Il existe différentes fonctions daffichage des biplots. Notez que leur longueur peut être magnifiée pour améliorer la visualisation. Lançons la fonction biplot pour créer un biplot de distance et un autre de corrélation. par(mfrow = c(1, 2)) biplot(vare_pca, scaling = 1, main = &quot;Biplot de distance&quot;) biplot(vare_pca, scaling = 2, main = &quot;Biplot de corrélation&quot;) Le biplot de distance permet de dégager les variables qui expliquent davantage la variabilité dans notre tableau : les clr du Fe et de lAl forment en grande partie le premier axe principal, alors que le clr du Mo forme en grande partie le second axe. Le biplot de corrélation montre que les clr du Fe et du Al sont corrélés dans le même sens, mais dans le sens contraire du clr du Mn. Linformation sur la teneur en Fe et celle de lAl est en grande partie redondante. Toutefois, le clr du Mo est presque indépendant du clr du Fe, ceux-ci étant à angle presque droit (~90°). Ces relations peuvent être explorées directement. par(mfrow = c(1, 2)) plot(vareclr$Al, vareclr$Fe) plot(vareclr$Mo, vareclr$Fe) Nous avons mentionné que lACP est une rotation. Prenons un second exemple pour bien en saisir les tenants et aboutissants. Le tableau de données que nous chargerons provient dune infographie dun dauphin, intitullée Bottlenose Dolphin, conçu par lartiste Tarnyloo. Les points correspondent à la surface dun dauphin. Jai ajouté une colonne anatomy, qui indique à quelle partie anatomique le point appartient. dolphin &lt;- read_csv(&quot;data/dolphin.csv&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## x = col_double(), ## y = col_double(), ## z = col_double(), ## anatomy = col_character() ## ) dolphin %&gt;% sample_n(5) ## # A tibble: 5 x 4 ## x y z anatomy ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 -0.172 -0.359 0.00655 Head ## 2 -0.0484 -0.467 -0.266 Head ## 3 0.160 -0.365 -0.0166 Head ## 4 -0.361 0.185 -0.351 Left pectoral fin ## 5 0.0753 -0.522 -0.0821 Head Voici en vue isométrique ce en quoi consiste ce nuage de points. library(&quot;scatterplot3d&quot;) scatterplot3d(x = dolphin$x, y = dolphin$y, z = dolphin$z, pch = 16, cex.symbols = 0.2) Effectuons lACP sur le dauphin. dolph_pca &lt;- rda(dolphin %&gt;% select(x, y, z), scale = FALSE) biplot(dolph_pca, scaling = 2) On ny voit pas grand chose, mais si lon extrait les scores et que lon raccourcit les vecteurs : dolph_scores &lt;- vegan::scores(dolph_pca, display = &quot;sites&quot;) dolph_loads &lt;- vegan::scores(dolph_pca, display = &quot;species&quot;) dolph_loads ## PC1 PC2 ## x -0.02990131 0.01608095 ## y -7.13731672 -1.43221776 ## z -4.56612084 2.23859843 ## attr(,&quot;const&quot;) ## [1] 9.089026 plot(dolph_scores, pch = 16, cex = 0.24, asp = 1, col = factor(dolphin$anatomy)) segments(x0 = rep(0, 3), y0 = rep(0, 3), x = dolph_loads[, 1]/50, y = dolph_loads[, 2]/50, col = &quot;chocolate&quot;, lwd = 4) La meilleure représentation du dauphin en \\(2D\\), selon la variance, est son profil - en effet, il est plus long et haut que large. Note. Une ACP effectue seulement une rotation des points. Les distances euclidiennes entre les points sont maintenues. Note. LACP a été conçue pour projetter en un nombre moindre de dimensions des observations dont les distributions sont multinormales (ce nest évidemment pas le cas du dauphin). Note. Les axes principaux dune ACP sont des variables aléatoires. Elles peuvent être assujetties à des tests ststistiques, des modèles, du partitionnement de données, etc. Excercice. Effectuez maintenant une ACP avec les données diris. 9.2.2 Analyse de correspondance (AC), encore AFC ? 9.2.2.1 Description Le but est aussi de résumer linformation contenue dans un tableau à plusieurs variables, mais en décrivant les relations entre les éléments-lignes (individus) et les éléments-colonnes (variables). Ainsi, lAFC est une sorte de double ACP en ce sens quelle sintéresse à la fois aux lignes et aux colonnes du tableau. Le tableau sur lequel sapplique lAFC est un tableau de contingence, cest-à-dire un tableau à double entrée avec des valeurs de comptage ou de fréquence absolues (données dabondance et doccurence) dans les cellules (Glèlè Kakai et al., 2016). Tout comme lACP, les données apportées vers une AC doivent être dimensionnellement homogènes, cest-à-dire que chaque variable doit être de même métrique : pour des données dabondance, cela signifie que les décomptes réfèrent tous au même concept : individus, colonies, surfaces occupées, etc. Alors que la distance euclidienne est préservée avec lACP, lAC préserve la distance du \\(\\chi^2\\), qui est insensible aux double-zéros. LAC produit \\(min(n,p)-1\\) axes principaux orthogonaux qui captent non pas le maximum de variance, mais la proportion de mesures aux carré par rapport à la somme des carrés de la matrice. Le biplot obtenu peut être présenté sous forme de biplot de site (scaling 1), où la distance du \\(\\chi^2\\) est préservée entre les sites ou de biplot despèces (scaling 2), ou la distance du \\(\\chi^2\\) est préservée entre les espèces. LAC hérite du coup une propriété importante de la distance du \\(\\chi^2\\), qui accorde davantage de distance entre un compte de 0 et de 1 quentre 1 et 2, et davantage entre 1 et 2 quentre 2 et 3. Par exemple, sur ces trois sites, on a compté un individu A de moins que les individus B. abundance_0123 = tibble(Site = c(&quot;Site 1&quot;, &quot;Site 2&quot;, &quot;Site 3&quot;), A = c(0, 1, 9), B = c(1, 2, 10)) abundance_0123 ## # A tibble: 3 x 3 ## Site A B ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Site 1 0 1 ## 2 Site 2 1 2 ## 3 Site 3 9 10 Pourtant, la distance du \\(\\chi^2\\) est plus élevée entre le site 1 et le site 2 quentre le site 2 et le site 3. dist(decostand(abundance_0123 %&gt;% select(-Site), method = &quot;chi.square&quot;)) ## 1 2 ## 2 0.6724111 ## 3 0.9555316 0.2831205 La distance du \\(\\chi^2\\) donne davantage dimportance aux espèces rares, ce dont une analyse doit tenir compte. Il pourrait être envisageable de retirer dun tableau des espèces rares, ou bien prétransformer des données dabondance par une transformation de Chord ou de Hellinger (tel que discuté au chapitre ), puis procéder à une ACP sur ces données (Legendre et Gallagher, 2001). 9.2.2.2 Application Le tableau varespec comprend des données de surface de couverture de 44 espèces de plantes en lien avec les données environnementales du tableau varechem. Ces données ont été publiées dans Väre et al. (1995) et exportées du module vegan. data(&quot;varespec&quot;) varespec %&gt;% sample_n(5) ## Callvulg Empenigr Rhodtome Vaccmyrt Vaccviti Pinusylv Descflex Betupube ## 19 0.00 8.92 0.00 2.42 10.28 0.12 0.02 0.00 ## 2 0.05 9.30 0.00 0.00 8.50 0.03 0.00 0.00 ## 25 0.00 6.93 0.00 0.00 10.60 0.02 0.10 0.02 ## 28 0.00 1.63 0.35 18.27 7.13 0.05 0.40 0.00 ## 4 3.40 0.63 0.00 0.00 1.98 0.05 0.05 0.00 ## Vacculig Diphcomp Dicrsp Dicrfusc Dicrpoly Hylosple Pleuschr Polypili ## 19 0.00 0.00 0.00 0.32 0.02 0.00 21.03 0.02 ## 2 0.00 0.00 0.00 0.03 0.00 0.00 0.75 0.00 ## 25 0.05 0.07 14.02 10.82 0.00 0.02 28.77 0.00 ## 28 0.20 0.00 0.30 0.52 0.20 9.97 70.03 0.00 ## 4 0.03 0.00 0.00 0.20 0.00 0.00 1.53 0.00 ## Polyjuni Polycomm Pohlnuta Ptilcili Barbhatc Cladarbu Cladrang Cladstel ## 19 1.58 0.18 0.07 0.27 0.02 7.23 4.95 22.08 ## 2 0.03 0.00 0.00 0.03 0.00 0.48 24.50 75.00 ## 25 6.98 0.13 0.00 0.22 0.00 6.00 2.25 0.00 ## 28 0.08 0.00 0.07 0.03 0.00 0.17 0.87 0.00 ## 4 0.10 0.00 0.05 0.00 0.00 15.73 20.03 28.20 ## Cladunci Cladcocc Cladcorn Cladgrac Cladfimb Cladcris Cladchlo Cladbotr ## 19 0.25 0.10 0.25 0.18 0.10 0.12 0.05 0.02 ## 2 0.20 0.00 0.03 0.03 0.05 0.03 0.03 0.00 ## 25 0.80 0.12 0.57 0.17 0.15 0.07 0.00 0.00 ## 28 0.05 0.02 0.03 0.07 0.10 0.02 0.00 0.02 ## 4 0.73 0.10 0.15 0.13 0.10 0.15 0.00 0.00 ## Cladamau Cladsp Cetreric Cetrisla Flavniva Nepharct Stersp Peltapht Icmaeric ## 19 0 0.00 0.00 0.00 0.02 0.00 0.28 0.00 0 ## 2 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0 ## 25 0 0.02 0.03 0.02 0.00 4.87 0.10 0.07 0 ## 28 0 0.00 0.00 0.02 0.00 0.00 0.02 0.00 0 ## 4 0 0.05 0.28 0.05 10.03 0.00 0.95 0.00 0 ## Cladcerv Claddefo Cladphyl ## 19 0.00 0.37 0 ## 2 0.03 0.03 0 ## 25 0.02 0.05 0 ## 28 0.00 0.08 0 ## 4 0.05 0.08 0 Pour effectuer lAC, nous utiliserons, comme pour lACP, le module vegan mais cette fois-ci avec la fonction cca(). LAC en scaling 1 est effectuée sur le tableau des abondances avec les espèces comme colonnes et les sites comme lignes. Les matrices dabondance transposées indiquent les sites où chaque espèce a été dénombrée : pour une analyse en scaling 2, on effectue une analyse de correspondance sur la matrice dabondance (ou doccurence) transposée. Pour chacune des AC, je filtre pour massurer que toutes les lignes contiennent au moins une observation. Ce nest pas nécessaire dans notre cas, mais je le laisse pour lexemple. vare_cca &lt;- cca(varespec %&gt;% filter(rowSums(.) &gt; 0)) summary(vare_cca, scaling = 1) ## ## Call: ## cca(X = varespec %&gt;% filter(rowSums(.) &gt; 0)) ## ## Partitioning of scaled Chi-square: ## Inertia Proportion ## Total 2.083 1 ## Unconstrained 2.083 1 ## ## Eigenvalues, and their contribution to the scaled Chi-square ## ## Importance of components: ## CA1 CA2 CA3 CA4 CA5 CA6 CA7 ## Eigenvalue 0.5249 0.3568 0.2344 0.19546 0.17762 0.12156 0.11549 ## Proportion Explained 0.2520 0.1713 0.1125 0.09383 0.08526 0.05835 0.05544 ## Cumulative Proportion 0.2520 0.4233 0.5358 0.62962 0.71489 0.77324 0.82868 ## CA8 CA9 CA10 CA11 CA12 CA13 CA14 ## Eigenvalue 0.08894 0.07318 0.05752 0.04434 0.02546 0.01710 0.014896 ## Proportion Explained 0.04269 0.03513 0.02761 0.02129 0.01222 0.00821 0.007151 ## Cumulative Proportion 0.87137 0.90650 0.93411 0.95539 0.96762 0.97583 0.982978 ## CA15 CA16 CA17 CA18 CA19 CA20 ## Eigenvalue 0.010160 0.007830 0.006032 0.004008 0.002865 0.0019275 ## Proportion Explained 0.004877 0.003759 0.002896 0.001924 0.001375 0.0009253 ## Cumulative Proportion 0.987855 0.991614 0.994510 0.996434 0.997809 0.9987341 ## CA21 CA22 CA23 ## Eigenvalue 0.0018074 0.0005864 0.0002434 ## Proportion Explained 0.0008676 0.0002815 0.0001168 ## Cumulative Proportion 0.9996017 0.9998832 1.0000000 ## ## Scaling 1 for species and site scores ## * Sites are scaled proportional to eigenvalues ## * Species are unscaled: weighted dispersion equal on all dimensions ## ## ## Species scores ## ## CA1 CA2 CA3 CA4 CA5 CA6 ## Callvulg 0.0303167 -1.597460 0.11455 -2.894569 0.1376073 2.291129 ## Empenigr 0.0751030 0.379305 0.39303 0.023675 0.8568729 -0.400964 ## Rhodtome 1.1052309 1.499299 3.04284 0.120106 3.2324306 -0.283510 ## Vaccmyrt 1.4614812 1.622935 2.72375 0.231688 0.4604556 0.712538 ## Vaccviti 0.1468014 0.313436 0.14696 0.243505 0.6868371 -0.147815 ## Pinusylv -0.4820096 0.588517 -0.36020 -0.127094 0.4064754 0.386604 ## Descflex 1.5348239 1.218806 1.87562 -0.001340 -1.3136979 -0.070731 ## Betupube 0.6694503 1.951826 3.84017 1.389423 7.5959115 -0.244478 ## Vacculig -0.0830789 -1.629259 1.05063 0.802648 -0.3058811 -1.625341 ## Diphcomp -0.5446464 -1.037570 0.52282 0.940275 0.3682126 -1.082929 ## Dicrsp 1.8120408 0.360290 -4.92082 3.088562 1.3867372 0.157815 ## Dicrfusc 1.2704743 -0.562978 -0.39718 -2.929542 0.3848272 -2.408710 ## Dicrpoly 0.7248118 1.409347 0.80341 1.915549 4.5674148 1.295447 ## Hylosple 2.0062408 1.743883 2.27549 0.928884 -3.7648428 2.254851 ## Pleuschr 1.3102086 0.583036 -0.01004 0.137298 -1.1216144 0.200422 ## Polypili -0.3805097 -1.243904 0.54593 1.477188 -0.7276341 -0.387641 ## Polyjuni 1.0133795 0.099043 -2.24697 1.510641 0.7729714 -3.062378 ## Polycomm 0.8468241 1.321773 1.13585 1.140723 2.6836594 -0.605038 ## Pohlnuta -0.0136453 0.589290 -0.35542 0.135481 0.9369707 0.397246 ## Ptilcili 0.4223631 1.598584 3.43474 1.400065 6.3209491 0.198935 ## Barbhatc 0.5018348 2.119334 4.57303 1.693188 8.1101807 0.645995 ## Cladarbu -0.1531729 -1.483884 0.20024 0.193680 0.0734141 0.358926 ## Cladrang -0.5502561 -1.084008 0.40552 0.724060 -0.3357992 -0.335924 ## Cladstel -1.4373146 1.077753 -0.44397 -0.375926 -0.2421525 0.004212 ## Cladunci 0.8151727 -1.006186 -1.82587 -1.389523 1.6046713 3.675908 ## Cladcocc -0.2133215 -0.584429 -0.21434 -0.567886 -0.0003788 -0.145303 ## Cladcorn 0.2631227 -0.177858 -0.44464 0.272422 0.3992282 -0.306738 ## Cladgrac 0.1956947 -0.311167 -0.23894 0.379013 0.4933026 0.037581 ## Cladfimb 0.0009213 -0.161418 0.18463 -0.435908 0.4831233 -0.143751 ## Cladcris 0.3373031 -0.470369 -0.05093 -0.823855 0.7182250 0.636140 ## Cladchlo -0.6200021 1.207278 0.21889 0.426447 1.9506082 0.120722 ## Cladbotr 0.5647242 1.047333 2.65330 0.907734 4.4946805 1.201655 ## Cladamau -0.6598144 -1.512880 0.83251 1.577699 -0.0407227 -1.419139 ## Cladsp -0.8209003 0.476164 -0.49752 -0.998241 -0.2393208 0.390785 ## Cetreric 0.2458192 -0.689228 -1.68427 -0.131681 0.7439412 2.374535 ## Cetrisla -0.3465221 1.362693 0.85897 0.396752 2.7526968 0.396591 ## Flavniva -1.4391907 -0.833589 -0.12919 0.007071 -1.4841375 2.956977 ## Nepharct 1.6813309 0.199484 -4.33509 2.229917 0.9561223 -5.472858 ## Stersp -0.5172793 -2.280900 0.99775 2.377013 -0.8892757 -1.441228 ## Peltapht 0.4035858 -0.043265 0.04538 0.711040 0.1824679 -0.841227 ## Icmaeric 0.0378754 -2.419595 0.72135 0.361302 -0.3736424 -2.092136 ## Cladcerv -0.9232858 -0.005233 -1.22058 0.305290 -0.8142627 0.414135 ## Claddefo 0.5190399 -0.496632 -0.15271 -0.695927 0.9042143 0.909191 ## Cladphyl -1.2836161 1.155872 -0.79912 -0.741170 -0.1608002 0.490526 ## ## ## Site scores (weighted averages of species scores) ## ## CA1 CA2 CA3 CA4 CA5 CA6 ## 18 -0.108122 -0.53705 0.229574 0.24412 0.1405624 -0.14253 ## 15 0.697118 -0.14441 -0.031788 -0.21743 -0.2738522 -0.08146 ## 24 0.987603 0.15042 -1.348447 0.80472 0.3095168 0.46773 ## 27 0.851765 0.49901 0.443559 0.12277 -0.4814871 0.07589 ## 23 0.359881 -0.05608 0.145813 0.15087 0.2405263 -0.17770 ## 19 0.003545 0.37017 0.027760 0.06168 -0.1158930 -0.03413 ## 22 0.860732 -0.11504 0.110869 -1.02169 0.0772348 -0.60530 ## 16 0.636936 -0.33250 0.001120 -0.79797 0.0130769 -0.54049 ## 28 1.279352 0.81557 0.670053 0.23137 -0.8929976 0.41783 ## 13 -0.195009 -0.80564 0.117686 -0.58286 -0.0007212 0.53071 ## 14 0.528532 -0.70420 -0.517771 -0.86836 0.5713441 0.91671 ## 20 0.382866 -0.18686 -0.004789 0.10156 0.0458125 0.21087 ## 25 0.990715 0.11967 -1.110040 0.44929 0.1885902 -0.70694 ## 7 -0.264704 -1.06013 0.334900 0.45973 -0.0326631 -0.19945 ## 5 -0.428410 -1.20765 0.374344 0.74970 -0.2596294 -0.30467 ## 6 -0.330534 -0.77498 0.130760 0.22391 0.0632686 0.09060 ## 3 -0.899601 0.12075 -0.075742 0.03842 -0.1489585 -0.12031 ## 4 -0.770294 -0.35351 -0.033779 -0.01795 -0.3007839 0.44303 ## 2 -0.992193 0.50319 -0.157505 -0.07070 -0.1065172 -0.09928 ## 9 -0.937173 0.78688 -0.258119 -0.19377 -0.0343535 -0.01259 ## 12 -0.726413 0.49163 -0.157235 -0.08698 -0.0105774 -0.02801 ## 10 -1.002083 0.71239 -0.236526 -0.18643 -0.0231666 -0.04928 ## 11 -0.322647 -0.03871 -0.001297 0.09029 -0.1481448 0.06934 ## 21 0.259527 0.80746 1.124258 0.36083 1.5437866 0.07051 varespec_eigenval &lt;- eigenvals(vare_cca, scaling = 1) prop_expl &lt;- varespec_eigenval / sum(varespec_eigenval) prop_expl ## CA1 CA2 CA3 CA4 CA5 CA6 CA7 ## 0.25198369 0.17127415 0.11253730 0.09382844 0.08526297 0.05835273 0.05543983 ## CA8 CA9 CA10 CA11 CA12 CA13 CA14 ## 0.04269324 0.03512634 0.02761013 0.02128559 0.01222326 0.00820997 0.00715069 ## CA15 CA16 CA17 CA18 CA19 CA20 CA21 ## 0.00487702 0.00375854 0.00289567 0.00192394 0.00137531 0.00092526 0.00086760 ## CA22 CA23 ## 0.00028148 0.00011683 par(mfrow = c(1, 2)) plot(x = 1:length(varespec_eigenval), y = vare_cca$CA$eig, type = &quot;b&quot;, xlab = &quot;Rang de la valeur propre&quot;, ylab = &quot;Valeur propre&quot;) abline(h = mean(varespec_eigenval), col = &quot;red&quot;, lty = 2) plot(x = 1:length(varespec_eigenval), y = prop_expl, type = &quot;b&quot;, xlab = &quot;Rang de la valeur propre&quot;, ylab = &quot;Proportion de la valeur propre&quot;) lines(x = 1:length(varespec_eigenval), y = broken_stick(length(varespec_eigenval)), col = &quot;red&quot;, lty = 2) Créons les biplots. par(mfrow = c(1, 2)) plot(vare_cca, scaling = 1, main = &quot;Biplot des espèces&quot;) plot(vare_cca, scaling = 2, main = &quot;Biplot des sites&quot;) Le biplot des espèces, à gauche (scaling = 1), montre la distribution des sites selon les espèces. Les emplacements des scores (en noir) montrent les contrastes entre sites selon les espèces qui les recouvrent. Les sites 14 et 15, par exemple, contrastent les sites 19, 20, 21 et 22 selon le 2ième axe principal. Par ailleurs, les axes principaux sont formé de plusieurs espèces dont aucune ne domine clairement. Le biplot des sites, à droite (scaling = 2), montre la distribution des recouvrements despèces selon les sites. Par exemple, les espèces Betupube (Betula pubescens) et Barbhatc (Barbilophozia hatcheri ) se recouvrent en particulier sur le site 24. Le site 1 est difficile à identifier, car il est couvert par plusieurs noms despèces, au bas au centre. Les sites 3 et 13 se confondent avec Dicrsp (une espèce de Dicranum) qui le recouvre amplement. Pour les deux types de biplot, les sites où les espèces situés près de lorigine, car ils peuvent être soit près de la moyenne, soit distribués uniformément. Le nombre de composantes à retenir peut être évalué par les approches Kaiser-Guttmann et broken-stick. scaling &lt;- 1 varespec_eigenval &lt;- eigenvals(vare_cca, scaling = scaling) # peut être effectué sur les deux types de scaling prop_expl &lt;- varespec_eigenval / sum(varespec_eigenval) par(mfrow = c(1, 2)) plot(x = 1:length(varespec_eigenval), y = vare_cca$CA$eig, type = &quot;b&quot;, xlab = &quot;Rang de la valeur propre&quot;, ylab = &quot;Valeur propre&quot;, main = paste(&quot;Eigenvalue - Kaiser-Guttmann, scaling =&quot;, scaling)) abline(h = mean(varespec_eigenval), col = &quot;red&quot;, lty = 2) plot(x = 1:length(varespec_eigenval), y = prop_expl, type = &quot;b&quot;, xlab = &quot;Rang de la valeur propre&quot;, ylab = &quot;Proportion&quot;, main = paste(&quot;Proportion - broken stick, scaling =&quot;, scaling)) lines(x = 1:length(varespec_eigenval), y = broken_stick(length(varespec_eigenval)), col = &quot;red&quot;, lty = 2) Pour les deux scalings, lapproche Kaiser-Guttmann propose 7 axes, tandis que lapproche broken-stick en propose 5. Les représentations biplot danalyse de correspondance peuvent prendre la forme dun boomerang, en particulier celles qui sont basées sur des données doccurence. Le tableau suivant initialement de Chessel et al. (1987) est distribué dans le module ade4. library(&quot;ade4&quot;) data(&quot;doubs&quot;) fish &lt;- doubs$fish doubs_cca &lt;- cca(fish %&gt;% filter(rowSums(.) &gt; 0)) plot(doubs_cca, scaling = 2) Les numéros de sites correspondent à la position dans une rivière, 1 étant en amont et 30 en aval. Le premier axe discrimine lamont et laval, tandis que le deuxième montre deux niches en amont. Bien que lon observe une discontinuité dans le cours deau, il y a une continuité dans les abondances. Cet effet peut être corrigé en retirant la tendance de lanalyse de correspondance par une detrended correspondance analysis (AC redressée). Pour cela, il faudra utiliser la fonction decorana(), ce qui ne sera pas couvert ici. Lanalyse des correspondances multiples (ACM) est utile pour lordination des données catégorielles (qualitatives). Le module ade4 est en mesure deffectuer des ACM, mais nest pas couvert dans ce manuel. Excercice. Effectuez et analysez une AC avec les données de recouvrement varespec. 9.2.3 Positionnement multidimensionnel (PoMd) 9.2.3.1 Description Le positionnement multidimensionnel (PoMd), ou Manifold Analysis, se base sur les assiciations entre les objets (mode Q) ou les variables (mode R) pour en réduire les dimensions. Alors que lACP conserve la distance euclidienne et que lAC conserve la distance du \\(\\chi^2\\), le PoMd conserve lassociation que vous sélectionnerez à votre convenance. Le PoMd vise à représenter en un nombre limité de dimensions (souvent 2) la distance (ou dissimilarité) quont des objets (ou des variables) les uns par rapport aux autres dans lespace multidimensionnel. Il existe deux types de PoMd : Le PoMd-métrique (metric multidimentional scaling MMDS, parfois le metric est retiré, MDS, et parfois lon parle de classic MDS) vise à représenter fidèlement la distance entre les objets ou les variables. Le PoMd-métrique ne devrait être utilisé que lorsque la métrique nest ni euclidienne, ni de \\(\\chi^2\\) et que lon désire préserver les distances entre les objets. Le PoMd-métrique est aussi appelé analyse en coordonnées principales (ACoP ou de langlais PCoA) . Le PoMd-non-métrique (nonmetric multidimentional scaling, NMDS) vise quant à lui à représenter lordre des distances entre les objets ou les variables. Cest une approche par rang : le PoMd-non-métrique vise à représenter les objets qui sont plus proches ou plus éloignées les uns des autres plutôt que de représenter leur similarité dans lespace multidimentionnelle. LIsoMap, pour isometric feature mapping, est une extension du PoMd qui reconstruit les distances selon les points retrouvés dans le voisinage. Les isomaps sont en mesure dapplatir des données ayant des formes complexes. Nous ne traitons pour linstant que des PoMd-métriques (fonction vegan::cmdscale()) et des PoMd-non-métriques (fonction vegan::metaMDS()). 9.2.3.2 Application Utilisons les données dabondance que nous avions au tout début du chapitre sur lassociation. La matrice dassociation de Bray-Curtis sera utilisée. abundance &lt;- tibble(&#39;Bruant familier&#39; = c(1, 0, 0, 3), &#39;Citelle à poitrine rousse&#39; = c(1, 0, 0, 0), &#39;Colibri à gorge rubis&#39; = c(0, 1, 0, 0), &#39;Geai bleu&#39; = c(3, 2, 0, 0), &#39;Bruant chanteur&#39; = c(1, 0, 5, 2), &#39;Chardonneret&#39; = c(0, 9, 6, 0), &#39;Bruant à gorge blanche&#39; = c(1, 0, 0, 0), &#39;Mésange à tête noire&#39; = c(20, 1, 1, 0), &#39;Jaseur boréal&#39; = c(66, 0, 0, 0)) assoc_mat &lt;- vegdist(abundance, method = &quot;bray&quot;) pheatmap::pheatmap(assoc_mat %&gt;% as.matrix(), cluster_rows = FALSE, cluster_cols = FALSE, display_numbers = round(assoc_mat %&gt;% as.matrix(), 2)) Les sites 2 et 3 devraient être plus près lun et lautre, puis les sites 3 et 4. Les autres associations sont éloignés denviron la même distance. Lançons le calcul de la PoMd-métrique. pcoa &lt;- cmdscale(assoc_mat, k = nrow(abundance)-1, eig = TRUE) spec_scores &lt;- wascores(pcoa$points, abundance) ordiplot(vegan::scores(pcoa), type = &#39;t&#39;, cex = 1.5) ## species scores not available text(spec_scores, row.names(spec_scores), col = &quot;red&quot;, cex = 0.75) On observe en effet que les sites 2 et 3 sont les plus près. Les sites 3 et 4sont plus éloignés. Les sites 1, 2 et 4 font à peu près un triangle équilatéral, ce qui correspond à ce à quoi on devrait sattendre. Les wa-scores permettent de juxtaposer les espèces sur les sites, pour référence. Le colibri nest présent que sur le site 2. Le site 1 est populé par des jaseurs et des mésanges, et cest le seul site où lon a observé une citelle. On a observé des chardonnerets sur les sites 2 et 3. Sur le site 4, on na observé que des bruants, que lon a aussi observé ailleurs, sauf au site 2. Le PoMd-non-métrique (non metric dimensional scaling, NMDS) fonctionne de la même manière que la PoMd-métrique, à la différence que la distance est basée sur les rangs. À cet égard, le site 4 à une distance de 0.76 du site 3, mais plutôt le deuxième plus loin, après le site 2 et avant le site 1. Utilisons la fonction metaMDS. nmds &lt;- metaMDS(assoc_mat, k = nrow(abundance)-1, eig = TRUE) ## Run 0 stress 0 ## Run 1 stress 0 ## ... Procrustes: rmse 0.1125059 max resid 0.1515484 ## Run 2 stress 0 ## ... Procrustes: rmse 0.0812906 max resid 0.09880211 ## Run 3 stress 0 ## ... Procrustes: rmse 0.09841779 max resid 0.1250949 ## Run 4 stress 0 ## ... Procrustes: rmse 0.09127989 max resid 0.1263639 ## Run 5 stress 0 ## ... Procrustes: rmse 0.09333172 max resid 0.1301158 ## Run 6 stress 0 ## ... Procrustes: rmse 0.09788884 max resid 0.1290237 ## Run 7 stress 0 ## ... Procrustes: rmse 0.08332084 max resid 0.1170185 ## Run 8 stress 0 ## ... Procrustes: rmse 0.1232397 max resid 0.1610021 ## Run 9 stress 0 ## ... Procrustes: rmse 0.1243441 max resid 0.1832939 ## Run 10 stress 0 ## ... Procrustes: rmse 0.1196666 max resid 0.1437585 ## Run 11 stress 0 ## ... Procrustes: rmse 0.1394643 max resid 0.1881232 ## Run 12 stress 0 ## ... Procrustes: rmse 0.04672541 max resid 0.05452668 ## Run 13 stress 0 ## ... Procrustes: rmse 0.150137 max resid 0.2007656 ## Run 14 stress 0 ## ... Procrustes: rmse 0.1311094 max resid 0.1769583 ## Run 15 stress 0 ## ... Procrustes: rmse 0.1871768 max resid 0.2407825 ## Run 16 stress 0 ## ... Procrustes: rmse 0.09646867 max resid 0.1226149 ## Run 17 stress 0 ## ... Procrustes: rmse 0.08459739 max resid 0.1087411 ## Run 18 stress 0 ## ... Procrustes: rmse 0.05523643 max resid 0.08409317 ## Run 19 stress 0 ## ... Procrustes: rmse 0.1068553 max resid 0.1353232 ## Run 20 stress 0 ## ... Procrustes: rmse 0.07617218 max resid 0.09825967 ## *** No convergence -- monoMDS stopping criteria: ## 20: stress &lt; smin ## Warning in metaMDS(assoc_mat, k = nrow(abundance) - 1, eig = TRUE): stress is ## (nearly) zero: you may have insufficient data spec_scores &lt;- wascores(nmds$points, abundance) ordiplot(vegan::scores(nmds), type = &#39;t&#39;, cex = 1.5) ## species scores not available text(spec_scores, row.names(spec_scores), col = &quot;red&quot;, cex = 0.75) Dans ce cas, entre PoMd-métrique et non-métrique, les résultats peuvent être interprétés de manière similaire. En ce qui a trait au dauphin, Pour plus de détails, je vous invite à vous référer à Borcard et al. (2011)) ou de consulter lexcellent site GUSTA ME. 9.2.4 Conclusion sur lordination non contraignante Lorsque les données sont euclidiennes, lanalyse en composantes principales (ACP) dervait être utilisée. Lorsque la métrique est celle du \\(\\chi^2\\), on préférera lanalyse de correspondance (AC). Si la métrique est autre, le positionnement multidimensionel (PoMd) est préférable. Dans ce dernier cas, si lon recherche une représentation simplifiée de la distance entre les objets ou variables, on utilisera un PoMd-métrique. À linverse, si lon désire une représentation plus fidèle au rang des distances, on préférera lPoMd-non-métrique. 9.3 Ordination contraignante Alors que lordination non contraignante vous permet de dresser un protrait de vos variables, lordination contraignante (ou canonique) permet de tester statistiquement ainsi que de représenter la relation entre plusieurs variables explicatives (par exemple, des conditions environnementales) et une ou plusieurs variables réponses (par exemple, les espèces observées). Lanalyse discriminante na fondamentalement quune seulement variable réponse, et celle-ci doit décrire lappartenance à une catégorie. Lanalyse de redondance sera préférée lorsque le nombre de variable est plus restreint (variables ionomiques et indicateurs de performance des cultures). Les détails, ainsi que les tenants et aboutissants de ces méthodes, sont présentés dans Numerical Ecology (Legendre et Legendre, 2012). Lanalyse canonique des corrélations sera préférée lorsque les variables sont parsemées (beaucoup de colonnes avec beaucoup de zéros, comme les variables dabondance). 9.3.1 Analyse discriminante Alors que lanalyse en composante principale vise à présenter la perspective (les axes) selon laquelle les points sont les plus éclatées, lanalyse discriminante, le plus souvent utilisé dans sa forme linéaire (ADL) et quadratique (ADQ), vise à présenter la perspective selon laquelle les groupes sont les plus éclatés, les groupes formant la variable contraignante. Ces groupes peuvent être connus (e.g. cultivar, région géographique) ou attribués (exemple: par partitionnement). LADL est parfois nommée analyse canonique de la variance. LAD vise à représenter des différences entre des groupes aux moyens de combinaisons linéaires (ADL) ou quadratique (ADQ) de variables mesurées. Sa représentation sous forme de biplot permet dapprécier les différences entre les groupes didentifier les variables qui sont responsables de la discrimination. Biplot de distance de lanalyse discriminante des ionomes despèces de plantes à fruits cultivées sauvages et domestiquées, Source: Parent et al. (2013) LADL a été développée par Fisher (1936), qui à titre dexemple dapplication a utilisé un jeu de données de dimensions diris collectées par Edgar Anderson, du Jardin botanique du Missouri, sur 150 spécimens diris collectés en Gaspésie (Est du Québec), ma région natale (suis-je assez chauvin?). Ce jeu de données est amplement utilisé à titre dexemple en analyse multivariée. Williams (1983) a présenté les tenants et aboutissants de lADL en écologie. Tout comme les données passant pas une ACP doivent suivre une distribution multinormale pour être statistiquement valide, les distributions des groupes dans une ADL doivent être multinormales et les variances des points par groupe doivent être homogènes ce qui est rarement le cas en science. Néanmoins: Heureusement, il y a des évidences dans la littérature que certaines dentre [ces règles] peuvent être transgressées modérément sans de grands changement dans les taux de classification. Cette conclusion dépends, toutefois, de la sévérité des transgressions, et de facteurs structueaux comme la position relative des moyennes des populations et de la nature des dispersions. - Williams (1983) LADL peut servir autant doutil dinterprétation que doutil de classification, cest à dire de prédire une catégorie selon les variables (chapitre ??). Dans les deux cas, lorsque le nombre de variables approchent le nombre dobservation, les résultats dune ADL risque dêtre difficilement interprétables. Le test approprié pour évaluer lhomodénéité de la covariance est le M-test de Box. Ce test est peu documenté dans la littérature, est rarement utilisé mais a la réputation dêtre particulièrement sévère. Il est rare que des données écologiques aient des dispersions (covariances) homogènes. Contrairement à lADL, lADQ ne demande pas à ce que les dispersions (covariances) soient homogènes. Néanmoins, lADQ ne génère ni de scores, ni de loadings: il sagit dun outil pour prédire des catégories (classification), non pas dun outil dordination. 9.3.1.1 Application Utilisons les données diris. data(&quot;iris&quot;) Testons la multinormalité par groupe. Rappelons-nous que pour considérer la distribution comme multinormale, la p-value de la distortion ainsi que la statistique de Kurtosis doivent être égale ou plus élevée que 0.05. La fonction split sépare le tableau en listes et la fonction map applique la fonction spécifiée à chaque élément de la liste. Cela permet deffectuer des tests de multinormalité sur chacune des espèces diris. iris %&gt;% split(.$Species) %&gt;% map(~ mvn(.x %&gt;% select(-Species), mvnTest = &quot;mardia&quot;)$multivariateNormality) ## $setosa ## Test Statistic p value Result ## 1 Mardia Skewness 25.6643445196298 0.177185884467652 YES ## 2 Mardia Kurtosis 1.29499223711605 0.195322907441935 YES ## 3 MVN &lt;NA&gt; &lt;NA&gt; YES ## ## $versicolor ## Test Statistic p value Result ## 1 Mardia Skewness 25.1850115362466 0.194444483140265 YES ## 2 Mardia Kurtosis -0.57186635893429 0.567412516528727 YES ## 3 MVN &lt;NA&gt; &lt;NA&gt; YES ## ## $virginica ## Test Statistic p value Result ## 1 Mardia Skewness 26.2705981752915 0.157059707690356 YES ## 2 Mardia Kurtosis 0.152614173978342 0.878702546726567 YES ## 3 MVN &lt;NA&gt; &lt;NA&gt; YES Le test est passé pour toutes les espèces. Voyons maintenant lhomogénéité de la covariance. Pour ce faire, nous aurons besoin de la fonction boxM, disponible avec le module biotools. Pour que les covariances soient considérées comme égales, la p-vaule doit être supérieure à 0.05. library(&quot;heplots&quot;) ## Loading required package: car ## Loading required package: carData ## ## Attaching package: &#39;car&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## recode ## The following object is masked from &#39;package:purrr&#39;: ## ## some boxM(iris %&gt;% select(-Species), group = iris$Species) ## ## Box&#39;s M-test for Homogeneity of Covariance Matrices ## ## data: iris %&gt;% select(-Species) ## Chi-Sq (approx.) = 140.94, df = 20, p-value &lt; 2.2e-16 On est loin dun cas où les distributions sont homogènes. Nous allons néanmoins procéder à lanalyse discriminante avec le module ade4. Nous aurons dabord besoin deffectuer une ACP avec la fonction dudi.pca de ade4 (en spécifiant une mise à léchelle), que nous projeterons en ADL avec discrimin. library(&quot;ade4&quot;) iris_pca &lt;- dudi.pca(df = iris %&gt;% select(-Species), scannf = FALSE, # ne pas générer de graphique scale = TRUE) iris_lda &lt;- discrimin(dudi = iris_pca, fac = iris$Species, scannf = FALSE) La visualisation peut être effectuée directement sur lobjet issu de la fonction discrimin. plot(iris_lda) Il sagit toutefois dune visualisation pour le diagnostic davantage que pour la publication. Si lobjectif est la pubilcation, vous pourriez utiliser la fonction plotDA que jai conçue à cet effet. Jai aussi conçu une fonction similaire qui utilise le module graphique de base de R. source(&quot;https://raw.githubusercontent.com/essicolo/AgFun/master/plotDA_gg.R&quot;) plotDA(scores = iris_lda$li, loadings = iris_lda$fa, fac = iris$Species, level=0.95, facname = &quot;Species&quot;, propLoadings = 1) ## Loading required package: ellipse ## ## Attaching package: &#39;ellipse&#39; ## The following object is masked from &#39;package:car&#39;: ## ## ellipse ## The following object is masked from &#39;package:graphics&#39;: ## ## pairs ## Loading required package: grid ## Loading required package: plyr ## ------------------------------------------------------------------------------ ## You have loaded plyr after dplyr - this is likely to cause problems. ## If you need functions from both plyr and dplyr, please load plyr first, then dplyr: ## library(plyr); library(dplyr) ## ------------------------------------------------------------------------------ ## ## Attaching package: &#39;plyr&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## arrange, count, desc, failwith, id, mutate, rename, summarise, ## summarize ## The following object is masked from &#39;package:purrr&#39;: ## ## compact À la différence de lACP, lADL maximise la sépatation des groupes. Nous avions noté avec lACP que les dimensions des pétales distingaient les groupes. Puisque nous avions justement des informations sur les groupes, nous aurions pu procéder directement à un ADL pour obtenir des conclusions plus directes. Si la longueur des pétales permet de distinguer lespèce setosa des deux autres, la largeur des pétales permet de distinguer virginica et versicolor, bien que les nuages de points se superposent. De manière bivariée, les régions de confiance des moyennes des scores discriminants (petites ellipses) montrent des différence significatives au seuil 0.05. Excercice. Si lon effectuait lADL sur notre dauphin, avec la colonne anatomy comme variable de regroupement, quobtiendrions-nous? Si lon consière la nageoire codale (queue) comme faisant partie du corps? Quelles sont les limitations? 9.3.2 Analyse de redondance (RDA) En anglais, on la nomme redundancy analysis, souvent abrégée RDA. Elle est utilisée pour résumer les relations linéaires entre des variables réponse et des variables explicatives. La redondance se situe dans lutilisation de deux tableaux de données contenant de linformation concordante. Lanalyse de redondance est une manière élégante deffectuer une régresssion linéaire multiple, où la matrice de valeurs prédites par la régression est assujettie à une analyse en composantes principales. Il est ainsi possible de superposer les scores des variables explicatives à ceux des variables réponse. Plus précisément, une RDA effectue les étapes suivantes (Borcard et al. (2011)) entre une matrice de variables indépendantes (explicatives) \\(X\\) et une matrice de variables dépendantes (réponse) \\(Y\\). 9.3.2.1 1. Régression entre \\(Y\\) et \\(X\\) Pour chacune des variables réponse de \\(Y\\) (\\(y_1\\), \\(y_2\\), , \\(y_j\\)), effectuer une régression linéaire sur les variables explicatives \\(X\\). \\[\\hat{y}_j = b_j + m_{1, j} \\times x_1 + m_{2, j} \\times x_2 + ... + m_{i, j} \\times x_i\\] \\[\\hat{y}_j = y_j + y_{res, j}\\] Pour chaque observation (\\(n\\)), nous obtenons une série de valeurs de \\(\\hat{y}_j\\) et de \\(y_{res, j}\\). Donc chaque cellule de la matrice \\(Y\\) a ses pendant \\(\\hat{y}\\) et \\(y_{res}\\). Nous obtenons ainsi une matrice de prédiction \\(\\hat{Y}\\) et une matrice des résidus \\(Y_{res} = Y - \\hat{Y}\\). 9.3.2.2 2. Analyse en composantes principales Ensuite, on effectue une analyse en composantes principales (ACP) sur la matrice des prédictions \\(\\hat{Y}\\). On obtient ainsi ses valeurs et vecteurs propres. Nommons \\(U\\) ses vecteurs propres. Les fonctions de RDA mettent souvent ces veceturs à léchelle avant de les retourner à lutilisateur. En ordination écologique, ces vecteurs mis à léchelle sont souvent appelés les scores des espèces, bien quil ne sagisse pas nécessairement despèces, mais plus généralement des variables de la matrice dépendante \\(Y\\). Il est aussi possible deffectuer une ACP sur \\(Y_{res}\\). 9.3.2.3 3. Calculer les scores Les vecteurs propres \\(U\\) sont utilisés pour calculer les scores des sites, \\(Y \\times U\\), ainsi que les contraintes de site \\(\\hat{Y} \\times U\\). 9.3.2.4 Application Nous allons utiliser la fonction rda du module vegan. En ce qui a trait aux données, utilisons les données varespec (matrice Y) et varechem (matrice X). La fonction rda peut fonctionner avec linterface-formule de R, où à gauche du ~ on retrouve le Y (la matrice de la communauté écologique, i.e. les abondances despèces) contre le X (l), à gauche, ce qui peut être pratique pour lanalyse dintéractions. Mais pour comparer deux matrices, nous pouvons définir X et Y. Ce qui est mélangeant, cest que vegan, contrairement aux conventions, défini X comme étant la matrice réponse et Y comme étant la matrice explicative. vare_rda &lt;- rda(X = varespec, Y = vareclr, scale = FALSE) par(mfrow = c(1, 2)) ordiplot(vare_rda, scaling = 1, type = &quot;text&quot;, main = &quot;Scaling 1: triplot de distance&quot;) ordiplot(vare_rda, scaling = 2, type = &quot;text&quot;, main = &quot;Scaling 2: triplot de corrélation&quot;) La fonction ordiplot permet de créer un triplot de base. La représentation des wascores est réputée plus robuste (moins susceptible dêtre bruitée), mais leur interprétation porte à confusion (Borcard et al. (2011)). Triplot de distance (scaling 1). Les angles entre les variables explicatives représentent leur corrélation (non pas les variables réponse). Triplot de corrélation (scaling 2). Les angles entre les variables représentent leurs corrélation, que les variables soient réponse ou explicative, ou entre variables réponses et variables explicatives. Les distances entre les objets sur le triplot ne sont pas des approximation de leur distance euclidienne. Les triplots montrent que les variables ont toutes un rôle important sur la dispersion des sites autours des axeds principaux. Le premier axe principal est composé de manière plus marquée par le clr de lAl et celui du Fe. Le deuxième axe principal est composé de manière plus marquée par le clr du S, du P et du K. Le triplot de corrélation ne présente pas de tendance appréciable pour la plupart des espèces, qui ne possèdent pas de niche particulière. Toutefois, lespèce Cladstel, présente surtout dans les sites 9 et 10, est liée à de basses teneurs en N et à de faibles valeurs de Baresoil (sol nu). Lespèce Pleuschr est liée à des sols où lon retrouve une grande épaisseur dhumus, ainsi que des teneurs élevées en nutriment K, P, S, Ca, Mg et Zn. Elle semble apprécier les sols à bas pH, mais à faible teneur en Fe et Al. La teneur en N lui semble plus indifférente (son vecteur étant presque perpendiculaire). On pourra personnaliser les graphiques en extrayant les scores. scaling &lt;- 2 sites &lt;- vegan::scores(vare_rda, display = &quot;wa&quot;, scaling = scaling) species &lt;- vegan::scores(vare_rda, display = &quot;species&quot;, scaling = scaling) env &lt;- vegan::scores(vare_rda, display = &quot;reg&quot;, scaling = scaling) plot(0, 0, type = &quot;n&quot;, xlim = c(-3, 5), ylim = c(-3, 4), asp = 1) abline(h=0, v = 0, col = &quot;grey80&quot;) text(sites/2, labels = rownames(sites), cex = 0.7, col = &quot;grey50&quot;) text(species/2, labels = rownames(species), col = &quot;green&quot;, cex = 0.7) segments(x0 = 0, y0 = 0, x = env[, 1], y = env[, 2], col = &quot;blue&quot;) text(env, labels = rownames(env), col = &quot;blue&quot;, cex = 1) On pourra effectuer une analyse de Kaiser-Guttmann ou de broken-stick de la même manière que précédemment. Étant une collection de régressions, une RDA est en mesure deffectuer des tests statistiques sur les coefficients de la régression en utilisant des permutations pour tester la signification des coefficients et des axes dune RDA. On doit néanmoins obligatoirement effectuer la RDA avec linterface formule. La variable de gaucheobjet à gauche du ~ peut être une matrice ou un tableau, et celui de droite est défini dans data. Le . dans linterface formule signifie une combinaison linéaire de toutes les variables, sans intéraction. vare_rda &lt;- rda(varespec ~ ., data = vareclr, scale = FALSE) perm_test_term &lt;- anova(vare_rda, by = &quot;term&quot;) #perm_test_axis &lt;- anova(vare_rda, by = &quot;axis&quot;) La signification des axes est difficile à interpréter. Toutefois, celui des variables présente un intérêt. perm_test_term ## Permutation test for rda under reduced model ## Terms added sequentially (first to last) ## Permutation: free ## Number of permutations: 999 ## ## Model: rda(formula = varespec ~ N + P + K + Ca + Mg + S + Al + Fe + Mn + Zn + Mo + Fv + Baresoil + Humdepth + pH, data = vareclr, scale = FALSE) ## Df Variance F Pr(&gt;F) ## N 1 216.13 4.8470 0.017 * ## P 1 272.71 6.1159 0.003 ** ## K 1 194.97 4.3724 0.012 * ## Ca 1 24.92 0.5589 0.672 ## Mg 1 52.61 1.1799 0.317 ## S 1 100.07 2.2441 0.117 ## Al 1 177.91 3.9900 0.020 * ## Fe 1 118.59 2.6595 0.062 . ## Mn 1 25.96 0.5822 0.646 ## Zn 1 35.81 0.8030 0.506 ## Mo 1 23.51 0.5273 0.673 ## Baresoil 1 98.64 2.2122 0.097 . ## Humdepth 1 43.59 0.9777 0.397 ## pH 1 38.93 0.8730 0.452 ## Residual 9 401.31 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 La p-value est la probabilité que les pentes calculées pour les variables émergent de distributions dont la moyenne est nulle. Au seuil 0.05, les variables significatives sont (les clr de) lazote, le phosphore, le potassium et laluminium. Dans le cas des matrices dabondance (ce nest pas le cas de varespec, constituée de données de recouvrement), il est préférable avec les RDA de les transformer préalablement avec la transformation compositionnelle, de chord ou de Hellinger (chapitre ??). Une autre option est deffectuer une RDA sur des matrices dassociation en passant par une analyse en coordonnées principales (Legendre et Anderson, 1999). Enfin, les données dabondance à létat brutes devraient plutôt passer utiliser une analyse canonique des corrélations. 9.3.3 Analyse canonique des correspondances (ACC) Lanalyse canonique des correspondances (Canonical correspondance analysis), ACC, a été à lorigine conçue pour étudier les liens entre des variables environnementales et labondance (décompte) ou loccurence (présence-absence) despèces (ter Braak, 1986). LACC est à la RDA ce que la CA est à lACP. Alors que la RDA préserve les distance euclidiennes entre variables dépendantes et indpendantes, lACC préserve les distances du \\(\\chi^2\\). Tout comme lAC, elle hérite du coup une propriété importate de la distance du \\(\\chi^2\\): il y a davantage davantage dimportance aux espèces rares. Lanalyse des correspondances canoniques est souvent utilisée dans la littérature, mais dans bien des cas une RDA sur des données dabondance transformées donnera des résultats davantage intérprétables (Legendre et Gallagher, 2001). 9.3.3.1 Application Cet exemple dapplication concerne des données dabondance. Nous allons conséquemment utiliser une CCA avec la fonction cca, toujours avec le module vegan. Les tableaux doubs_fish et doubs_env comprennent respectivement des données dabondance despèces de poissons et dans différents environnements de la rivière Doubs (Europe) publiées dans Verneaux. (1973) et exportées du module ade4. data(&quot;doubs&quot;) doubs_fish &lt;- doubs$fish doubs_env &lt;- doubs$env Sur le site no 8, aucun poisson na pas été observé. Les observations ne comprenant que des zéro doivent être préalablement retirées. tot_spec &lt;- doubs_fish %&gt;% transmute(tot_spec = apply(., 1, sum)) doubs_fish &lt;- doubs_fish %&gt;% filter(tot_spec != 0) doubs_env &lt;- doubs_env %&gt;% filter(tot_spec != 0) De la même manière quavec la fonction rda de vegan, nous utilisons cca pour lACC. doubs_cca &lt;- cca(doubs_fish ~ ., data = doubs_env, scale = FALSE) Comparons les résultats par(mfrow = c(1, 2)) ordiplot(doubs_cca, scaling = 1, type = &quot;text&quot;, main = &quot;CCA - Scaling 1 - Triplot de distance&quot;) ordiplot(doubs_cca, scaling = 2, type = &quot;text&quot;, main = &quot;CCA - Scaling 2 - Triplot de corrélation&quot;) Triplot de distance (scaling 1). La projection des variables réponse à angle droit sur les variables explicatives est une approximation de la réponse sur lexplication. (2) Un objet (site ou réponse) situé près dune variable explicative est plus susceptible davoir le décompte 1. (3) Les distances entre les variables (réponse et explicatives) approximent la distance du \\(\\chi^2\\) (traduction adaptée de Borcard et al. (2011)). Triplot de corrélation (scaling 2). La valeur optmiale de lespèce sur une variable environnementale quantitative peut être obtenue en projetant lespèce à angle droit sur la variable. (2) Une espèce se trouvant près dune variable environnementale est susceptible de se trouver en plus grande abondance aux sites de statut 1 pour cette variable. (3) Les distances napproximent pas la distance du \\(\\chi^2\\) (traduction adaptée de Borcard et al. (2011)). "]]
